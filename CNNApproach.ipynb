{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNApproach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjsiH15sXp3E",
        "colab_type": "text"
      },
      "source": [
        "# **CNN for Human Activity Recognition with MHEALTH dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN3Gb_ZCXyha",
        "colab_type": "text"
      },
      "source": [
        "Importing all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQJjFxC2h8Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout2d\n",
        "from torch.optim import Adam, SGD\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXw9BHZlYnYC",
        "colab_type": "text"
      },
      "source": [
        "# **Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ6XlRTclrTR",
        "colab_type": "code",
        "outputId": "f32ca529-c347-40c3-bd66-eb3f2456bbdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT9CEUxXYG5F",
        "colab_type": "text"
      },
      "source": [
        "Loading all files and creating train, validation and test sets (60/20/20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apj8iuKQiD3n",
        "colab_type": "code",
        "outputId": "5c43e78f-4417-4725-d7a5-341109524936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sensors_data1 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject1.csv')\n",
        "sensors_data2 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject2.csv')\n",
        "sensors_data3 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject3.csv')\n",
        "sensors_data4 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject4.csv')\n",
        "sensors_data5 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject5.csv')\n",
        "sensors_data6 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject6.csv')\n",
        "sensors_data7 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject7.csv')\n",
        "sensors_data8 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject8.csv')\n",
        "sensors_data9 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject9.csv')\n",
        "sensors_data10 = pd.read_csv('drive/My Drive/ML final project/mHealth_subject10.csv')\n",
        "\n",
        "x_train = pd.concat([sensors_data1, sensors_data2, sensors_data3, sensors_data4, sensors_data5, sensors_data6])\n",
        "y_train = x_train.Label\n",
        "x_val = pd.concat([sensors_data7, sensors_data8])\n",
        "y_val = x_val.Label\n",
        "x_test = pd.concat([sensors_data9, sensors_data10])\n",
        "y_test = x_test.Label\n",
        "\n",
        "\n",
        "\n",
        "print(\"x_train shape = \", x_train.shape)\n",
        "print(\"y_train shape =\",y_train.shape)\n",
        "\n",
        "print(\"x_val shape =\" ,x_val.shape)\n",
        "print(\"y_val shape =\",y_val.shape)\n",
        "\n",
        "print(\"x_test shape =\" ,x_test.shape)\n",
        "print(\"y_test shape =\",y_test.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape =  (748801, 25)\n",
            "y_train shape = (748801,)\n",
            "x_val shape = (233472, 25)\n",
            "y_val shape = (233472,)\n",
            "x_test shape = (233472, 25)\n",
            "y_test shape = (233472,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooppgXErMYKj",
        "colab_type": "code",
        "outputId": "36a36fca-f7d3-44b5-e5bc-a3901c2e6d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "x_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>acChestX</th>\n",
              "      <th>acChestY</th>\n",
              "      <th>acChestZ</th>\n",
              "      <th>ecgLead1</th>\n",
              "      <th>ecgLead2</th>\n",
              "      <th>acLAnkleX</th>\n",
              "      <th>acLAnkleY</th>\n",
              "      <th>acLAnkleZ</th>\n",
              "      <th>gyrLAnkleX</th>\n",
              "      <th>gyrLAnkleY</th>\n",
              "      <th>gyrLAnkleZ</th>\n",
              "      <th>mLAnkleX</th>\n",
              "      <th>mLAnkleY</th>\n",
              "      <th>mLAnkleZ</th>\n",
              "      <th>acRightLowerArmX</th>\n",
              "      <th>acRightLowerArmY</th>\n",
              "      <th>acRightLowerArmZ</th>\n",
              "      <th>gyrRightLowerArmX</th>\n",
              "      <th>gyrRightLowerArmY</th>\n",
              "      <th>gyrRightLowerArmZ</th>\n",
              "      <th>mRightLowerArmX</th>\n",
              "      <th>mRightLowerArmY</th>\n",
              "      <th>mRightLowerArmZ</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-9.5767</td>\n",
              "      <td>-1.466100</td>\n",
              "      <td>-0.34247</td>\n",
              "      <td>-0.087912</td>\n",
              "      <td>0.037677</td>\n",
              "      <td>0.37048</td>\n",
              "      <td>-10.0150</td>\n",
              "      <td>0.50297</td>\n",
              "      <td>0.51206</td>\n",
              "      <td>-0.81426</td>\n",
              "      <td>-0.46365</td>\n",
              "      <td>0.37877</td>\n",
              "      <td>0.730160</td>\n",
              "      <td>-0.59208</td>\n",
              "      <td>-3.7504</td>\n",
              "      <td>-8.9035</td>\n",
              "      <td>0.64857</td>\n",
              "      <td>0.313730</td>\n",
              "      <td>-1.08830</td>\n",
              "      <td>0.32759</td>\n",
              "      <td>0.54755</td>\n",
              "      <td>0.89477</td>\n",
              "      <td>-0.72002</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-9.5928</td>\n",
              "      <td>-1.170000</td>\n",
              "      <td>-0.67372</td>\n",
              "      <td>-0.108840</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>0.37621</td>\n",
              "      <td>-9.8393</td>\n",
              "      <td>0.23055</td>\n",
              "      <td>0.51206</td>\n",
              "      <td>-0.81426</td>\n",
              "      <td>-0.46365</td>\n",
              "      <td>0.20671</td>\n",
              "      <td>0.364910</td>\n",
              "      <td>-0.87358</td>\n",
              "      <td>-3.7264</td>\n",
              "      <td>-8.8417</td>\n",
              "      <td>0.82875</td>\n",
              "      <td>0.313730</td>\n",
              "      <td>-1.08830</td>\n",
              "      <td>0.32759</td>\n",
              "      <td>0.54758</td>\n",
              "      <td>0.89837</td>\n",
              "      <td>-0.35904</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-9.8840</td>\n",
              "      <td>-1.255500</td>\n",
              "      <td>-0.49195</td>\n",
              "      <td>-0.100470</td>\n",
              "      <td>0.037677</td>\n",
              "      <td>0.35848</td>\n",
              "      <td>-9.7266</td>\n",
              "      <td>0.61101</td>\n",
              "      <td>0.51206</td>\n",
              "      <td>-0.81426</td>\n",
              "      <td>-0.46365</td>\n",
              "      <td>0.55505</td>\n",
              "      <td>0.728390</td>\n",
              "      <td>-0.45129</td>\n",
              "      <td>-3.7811</td>\n",
              "      <td>-8.9232</td>\n",
              "      <td>0.67884</td>\n",
              "      <td>0.313730</td>\n",
              "      <td>-1.08830</td>\n",
              "      <td>0.32759</td>\n",
              "      <td>0.54577</td>\n",
              "      <td>0.71692</td>\n",
              "      <td>-0.35726</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-9.5893</td>\n",
              "      <td>-1.345500</td>\n",
              "      <td>-0.28952</td>\n",
              "      <td>0.071167</td>\n",
              "      <td>0.163270</td>\n",
              "      <td>0.36937</td>\n",
              "      <td>-9.8759</td>\n",
              "      <td>0.53073</td>\n",
              "      <td>0.51206</td>\n",
              "      <td>-0.81426</td>\n",
              "      <td>-0.46365</td>\n",
              "      <td>0.38299</td>\n",
              "      <td>0.363140</td>\n",
              "      <td>-0.73279</td>\n",
              "      <td>-3.8521</td>\n",
              "      <td>-8.9727</td>\n",
              "      <td>0.72845</td>\n",
              "      <td>0.315690</td>\n",
              "      <td>-1.08420</td>\n",
              "      <td>0.32328</td>\n",
              "      <td>0.54577</td>\n",
              "      <td>0.71692</td>\n",
              "      <td>-0.35726</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-9.8028</td>\n",
              "      <td>-1.274400</td>\n",
              "      <td>-0.54627</td>\n",
              "      <td>1.063300</td>\n",
              "      <td>0.502350</td>\n",
              "      <td>0.33570</td>\n",
              "      <td>-9.8390</td>\n",
              "      <td>0.26141</td>\n",
              "      <td>0.49722</td>\n",
              "      <td>-0.81614</td>\n",
              "      <td>-0.46365</td>\n",
              "      <td>0.20244</td>\n",
              "      <td>0.548430</td>\n",
              "      <td>-0.73103</td>\n",
              "      <td>-3.7814</td>\n",
              "      <td>-9.0327</td>\n",
              "      <td>0.72545</td>\n",
              "      <td>0.315690</td>\n",
              "      <td>-1.08420</td>\n",
              "      <td>0.32328</td>\n",
              "      <td>0.54395</td>\n",
              "      <td>0.53547</td>\n",
              "      <td>-0.35549</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98299</th>\n",
              "      <td>98299</td>\n",
              "      <td>-9.2476</td>\n",
              "      <td>-0.248070</td>\n",
              "      <td>-2.62230</td>\n",
              "      <td>0.230250</td>\n",
              "      <td>0.234430</td>\n",
              "      <td>1.78490</td>\n",
              "      <td>-9.8287</td>\n",
              "      <td>0.29725</td>\n",
              "      <td>-0.34137</td>\n",
              "      <td>-0.90056</td>\n",
              "      <td>-0.61493</td>\n",
              "      <td>-0.68764</td>\n",
              "      <td>0.557340</td>\n",
              "      <td>-1.14620</td>\n",
              "      <td>-3.7198</td>\n",
              "      <td>-8.9071</td>\n",
              "      <td>0.29423</td>\n",
              "      <td>0.041176</td>\n",
              "      <td>-0.99384</td>\n",
              "      <td>-0.48060</td>\n",
              "      <td>2.40890</td>\n",
              "      <td>7.49610</td>\n",
              "      <td>7.91550</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98300</th>\n",
              "      <td>98300</td>\n",
              "      <td>-9.4632</td>\n",
              "      <td>-0.073513</td>\n",
              "      <td>-2.11190</td>\n",
              "      <td>0.276300</td>\n",
              "      <td>0.284670</td>\n",
              "      <td>1.86870</td>\n",
              "      <td>-9.8766</td>\n",
              "      <td>0.46236</td>\n",
              "      <td>-0.34137</td>\n",
              "      <td>-0.90056</td>\n",
              "      <td>-0.61493</td>\n",
              "      <td>-0.86819</td>\n",
              "      <td>0.742630</td>\n",
              "      <td>-1.14450</td>\n",
              "      <td>-3.7160</td>\n",
              "      <td>-8.7455</td>\n",
              "      <td>0.44814</td>\n",
              "      <td>0.041176</td>\n",
              "      <td>-0.99384</td>\n",
              "      <td>-0.48060</td>\n",
              "      <td>1.69450</td>\n",
              "      <td>7.86600</td>\n",
              "      <td>7.89750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98301</th>\n",
              "      <td>98301</td>\n",
              "      <td>-9.4011</td>\n",
              "      <td>-0.144580</td>\n",
              "      <td>-3.02350</td>\n",
              "      <td>0.288850</td>\n",
              "      <td>0.301410</td>\n",
              "      <td>1.69280</td>\n",
              "      <td>-9.9290</td>\n",
              "      <td>0.16631</td>\n",
              "      <td>-0.34137</td>\n",
              "      <td>-0.90056</td>\n",
              "      <td>-0.61493</td>\n",
              "      <td>-0.86841</td>\n",
              "      <td>0.008684</td>\n",
              "      <td>-1.13710</td>\n",
              "      <td>-3.8824</td>\n",
              "      <td>-9.1155</td>\n",
              "      <td>0.45048</td>\n",
              "      <td>0.041176</td>\n",
              "      <td>-0.99384</td>\n",
              "      <td>-0.48060</td>\n",
              "      <td>1.15770</td>\n",
              "      <td>8.05280</td>\n",
              "      <td>7.88490</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98302</th>\n",
              "      <td>98302</td>\n",
              "      <td>-9.3732</td>\n",
              "      <td>-0.026252</td>\n",
              "      <td>-2.70760</td>\n",
              "      <td>0.351650</td>\n",
              "      <td>0.347460</td>\n",
              "      <td>1.52790</td>\n",
              "      <td>-9.6306</td>\n",
              "      <td>0.30458</td>\n",
              "      <td>-0.34137</td>\n",
              "      <td>-0.90056</td>\n",
              "      <td>-0.61493</td>\n",
              "      <td>-0.33979</td>\n",
              "      <td>-0.730550</td>\n",
              "      <td>-0.70740</td>\n",
              "      <td>-3.5564</td>\n",
              "      <td>-9.1441</td>\n",
              "      <td>0.59488</td>\n",
              "      <td>0.041176</td>\n",
              "      <td>-0.99384</td>\n",
              "      <td>-0.48060</td>\n",
              "      <td>0.27441</td>\n",
              "      <td>9.48790</td>\n",
              "      <td>5.32580</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98303</th>\n",
              "      <td>98303</td>\n",
              "      <td>-9.3518</td>\n",
              "      <td>-0.592450</td>\n",
              "      <td>-2.63230</td>\n",
              "      <td>0.280480</td>\n",
              "      <td>0.272110</td>\n",
              "      <td>1.66140</td>\n",
              "      <td>-9.8398</td>\n",
              "      <td>0.18088</td>\n",
              "      <td>-0.33210</td>\n",
              "      <td>-0.90432</td>\n",
              "      <td>-0.61886</td>\n",
              "      <td>-0.15923</td>\n",
              "      <td>-0.915840</td>\n",
              "      <td>-0.70916</td>\n",
              "      <td>-3.9035</td>\n",
              "      <td>-8.9324</td>\n",
              "      <td>0.76171</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>-1.02050</td>\n",
              "      <td>-0.47198</td>\n",
              "      <td>-0.98056</td>\n",
              "      <td>9.66360</td>\n",
              "      <td>3.49390</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>233472 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  acChestX  acChestY  ...  mRightLowerArmY  mRightLowerArmZ  Label\n",
              "0               0   -9.5767 -1.466100  ...          0.89477         -0.72002      0\n",
              "1               1   -9.5928 -1.170000  ...          0.89837         -0.35904      0\n",
              "2               2   -9.8840 -1.255500  ...          0.71692         -0.35726      0\n",
              "3               3   -9.5893 -1.345500  ...          0.71692         -0.35726      0\n",
              "4               4   -9.8028 -1.274400  ...          0.53547         -0.35549      0\n",
              "...           ...       ...       ...  ...              ...              ...    ...\n",
              "98299       98299   -9.2476 -0.248070  ...          7.49610          7.91550      0\n",
              "98300       98300   -9.4632 -0.073513  ...          7.86600          7.89750      0\n",
              "98301       98301   -9.4011 -0.144580  ...          8.05280          7.88490      0\n",
              "98302       98302   -9.3732 -0.026252  ...          9.48790          5.32580      0\n",
              "98303       98303   -9.3518 -0.592450  ...          9.66360          3.49390      0\n",
              "\n",
              "[233472 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twz0rCJIYRON",
        "colab_type": "text"
      },
      "source": [
        "Dropping first column with iterations number, column with the label and colums for ECG leads data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0zKP7ZysVUb",
        "colab_type": "code",
        "outputId": "7424ad33-7cfd-481b-9ce2-9189bf37d2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x_train.drop(x_train.columns[[0, 4, 5, 24]], axis=1, inplace= True)\n",
        "x_val.drop(x_val.columns[[0, 4, 5, 24]], axis=1, inplace= True)\n",
        "x_test.drop(x_test.columns[[0, 4, 5, 24]], axis=1, inplace= True)\n",
        "\n",
        "\n",
        "print(\"x_train shape = \", x_train.shape)\n",
        "print(\"y_train shape =\",y_train.shape)\n",
        "\n",
        "print(\"x_test shape =\" ,x_val.shape)\n",
        "print(\"y_test shape =\",y_val.shape)\n",
        "\n",
        "print(\"x_test shape =\" ,x_test.shape)\n",
        "print(\"y_test shape =\",y_test.shape)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape =  (748801, 21)\n",
            "y_train shape = (748801,)\n",
            "x_test shape = (233472, 21)\n",
            "y_test shape = (233472,)\n",
            "x_test shape = (233472, 21)\n",
            "y_test shape = (233472,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4QPpsS-YykZ",
        "colab_type": "text"
      },
      "source": [
        "Data segmentation: splitting data along the temporal axis.\n",
        "\n",
        "Window size = 50 with step = 25 (%50 of window size).\n",
        "\n",
        "Label for each window is the labek of the most frequent activity in the given time period."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC5RdU-HtQCf",
        "colab_type": "code",
        "outputId": "8038626b-0ff4-42b6-df65-1400cdec373e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def windowz(data, size, step):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "        yield start, start + size\n",
        "        start += step\n",
        "\n",
        "def segment_opp(inputs, targets, window_size, step):\n",
        "    segments = np.zeros(((len(inputs) - window_size) // step + 1, window_size, 21))\n",
        "    labels = np.zeros(((len(targets) - window_size) // step + 1))\n",
        "    i_segment = 0\n",
        "    i_label = 0\n",
        "    for (start, end) in windowz(inputs, window_size, step):\n",
        "        if(len(inputs[start:end]) == window_size):\n",
        "            m = stats.mode(y_train[start:end])\n",
        "            segments[i_segment] = x_train[start:end]\n",
        "            labels[i_label] = m[0]\n",
        "            i_label+=1\n",
        "            i_segment+=1\n",
        "    return segments, labels\n",
        "\n",
        "\n",
        "window_size = 50\n",
        "step = 25\n",
        "print(\"segmenting signal...\")\n",
        "train_x, train_y = segment_opp(x_train, y_train, window_size, step)\n",
        "val_x, val_y = segment_opp(x_val, y_val, window_size, step)\n",
        "test_x, test_y = segment_opp(x_test, y_test, window_size, step)\n",
        "print(\"signal segmented.\")\n",
        "print(\"Shape of segmented train inputs: {}\".format(train_x.shape))\n",
        "print(\"Shape of segmented train labels: {}\".format(train_y.shape))\n",
        "\n",
        "print(\"Shape of segmented test inputs:  {}\".format(val_x.shape))\n",
        "print(\"Shape of segmented test labels:  {}\".format(val_y.shape))\n",
        "\n",
        "print(\"Shape of segmented test inputs:  {}\".format(test_x.shape))\n",
        "print(\"Shape of segmented test labels:  {}\".format(test_y.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "segmenting signal...\n",
            "signal segmented.\n",
            "Shape of segmented train inputs: (29951, 50, 21)\n",
            "Shape of segmented train labels: (29951,)\n",
            "Shape of segmented test inputs:  (9337, 50, 21)\n",
            "Shape of segmented test labels:  (9337,)\n",
            "Shape of segmented test inputs:  (9337, 50, 21)\n",
            "Shape of segmented test labels:  (9337,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vqwaicVGP0i",
        "colab_type": "code",
        "outputId": "5ca87639-2853-467a-b77c-90acbecec261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "x_val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acChestX</th>\n",
              "      <th>acChestY</th>\n",
              "      <th>acChestZ</th>\n",
              "      <th>acLAnkleX</th>\n",
              "      <th>acLAnkleY</th>\n",
              "      <th>acLAnkleZ</th>\n",
              "      <th>gyrLAnkleX</th>\n",
              "      <th>gyrLAnkleY</th>\n",
              "      <th>gyrLAnkleZ</th>\n",
              "      <th>mLAnkleX</th>\n",
              "      <th>mLAnkleY</th>\n",
              "      <th>mLAnkleZ</th>\n",
              "      <th>acRightLowerArmX</th>\n",
              "      <th>acRightLowerArmY</th>\n",
              "      <th>acRightLowerArmZ</th>\n",
              "      <th>gyrRightLowerArmX</th>\n",
              "      <th>gyrRightLowerArmY</th>\n",
              "      <th>gyrRightLowerArmZ</th>\n",
              "      <th>mRightLowerArmX</th>\n",
              "      <th>mRightLowerArmY</th>\n",
              "      <th>mRightLowerArmZ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9.5409</td>\n",
              "      <td>-1.23920</td>\n",
              "      <td>-0.77468</td>\n",
              "      <td>2.3448</td>\n",
              "      <td>-9.6597</td>\n",
              "      <td>1.353000</td>\n",
              "      <td>0.781080</td>\n",
              "      <td>-0.52158</td>\n",
              "      <td>-0.049116</td>\n",
              "      <td>0.026045</td>\n",
              "      <td>0.18323</td>\n",
              "      <td>-0.86815</td>\n",
              "      <td>-7.0806</td>\n",
              "      <td>-6.6875</td>\n",
              "      <td>2.2490</td>\n",
              "      <td>-0.64902</td>\n",
              "      <td>-0.13758</td>\n",
              "      <td>0.82328</td>\n",
              "      <td>-1.6286</td>\n",
              "      <td>-1.2796</td>\n",
              "      <td>-2.5469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9.5641</td>\n",
              "      <td>-1.59150</td>\n",
              "      <td>-0.92218</td>\n",
              "      <td>2.0888</td>\n",
              "      <td>-9.4906</td>\n",
              "      <td>1.431800</td>\n",
              "      <td>0.779220</td>\n",
              "      <td>-0.52533</td>\n",
              "      <td>-0.039293</td>\n",
              "      <td>0.378720</td>\n",
              "      <td>0.54667</td>\n",
              "      <td>-0.59024</td>\n",
              "      <td>-6.8389</td>\n",
              "      <td>-6.5352</td>\n",
              "      <td>2.4753</td>\n",
              "      <td>-0.64902</td>\n",
              "      <td>-0.13758</td>\n",
              "      <td>0.82328</td>\n",
              "      <td>-1.2749</td>\n",
              "      <td>-1.8203</td>\n",
              "      <td>-1.8124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9.5849</td>\n",
              "      <td>-1.56120</td>\n",
              "      <td>-0.94051</td>\n",
              "      <td>2.1386</td>\n",
              "      <td>-9.4919</td>\n",
              "      <td>1.307200</td>\n",
              "      <td>0.779220</td>\n",
              "      <td>-0.52533</td>\n",
              "      <td>-0.039293</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>0.54491</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>-6.6737</td>\n",
              "      <td>-6.6865</td>\n",
              "      <td>2.3532</td>\n",
              "      <td>-0.64902</td>\n",
              "      <td>-0.13758</td>\n",
              "      <td>0.82328</td>\n",
              "      <td>-1.4563</td>\n",
              "      <td>-1.9999</td>\n",
              "      <td>-1.8142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9.7097</td>\n",
              "      <td>-1.38230</td>\n",
              "      <td>-0.77703</td>\n",
              "      <td>2.2127</td>\n",
              "      <td>-9.6292</td>\n",
              "      <td>1.436500</td>\n",
              "      <td>0.779220</td>\n",
              "      <td>-0.52533</td>\n",
              "      <td>-0.039293</td>\n",
              "      <td>0.555050</td>\n",
              "      <td>0.72839</td>\n",
              "      <td>-0.45129</td>\n",
              "      <td>-6.7865</td>\n",
              "      <td>-6.4962</td>\n",
              "      <td>2.3835</td>\n",
              "      <td>-0.63922</td>\n",
              "      <td>-0.14579</td>\n",
              "      <td>0.83621</td>\n",
              "      <td>-1.4509</td>\n",
              "      <td>-1.4592</td>\n",
              "      <td>-2.1805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9.7578</td>\n",
              "      <td>-1.50300</td>\n",
              "      <td>-0.87211</td>\n",
              "      <td>2.2195</td>\n",
              "      <td>-9.6426</td>\n",
              "      <td>1.081700</td>\n",
              "      <td>0.779220</td>\n",
              "      <td>-0.52533</td>\n",
              "      <td>-0.039293</td>\n",
              "      <td>0.382990</td>\n",
              "      <td>0.36314</td>\n",
              "      <td>-0.73279</td>\n",
              "      <td>-6.6627</td>\n",
              "      <td>-6.4775</td>\n",
              "      <td>2.2490</td>\n",
              "      <td>-0.63922</td>\n",
              "      <td>-0.14579</td>\n",
              "      <td>0.83621</td>\n",
              "      <td>-1.0881</td>\n",
              "      <td>-1.0890</td>\n",
              "      <td>-1.0939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129019</th>\n",
              "      <td>-5.8140</td>\n",
              "      <td>-0.21063</td>\n",
              "      <td>1.10740</td>\n",
              "      <td>2.4278</td>\n",
              "      <td>-9.5092</td>\n",
              "      <td>-1.419900</td>\n",
              "      <td>-0.087199</td>\n",
              "      <td>-0.61351</td>\n",
              "      <td>-0.913560</td>\n",
              "      <td>-31.373000</td>\n",
              "      <td>-36.56700</td>\n",
              "      <td>-1.17140</td>\n",
              "      <td>-6.5514</td>\n",
              "      <td>5.1998</td>\n",
              "      <td>-2.0213</td>\n",
              "      <td>-0.68431</td>\n",
              "      <td>-0.10678</td>\n",
              "      <td>-0.73276</td>\n",
              "      <td>19.3450</td>\n",
              "      <td>13.5280</td>\n",
              "      <td>29.1320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129020</th>\n",
              "      <td>-5.4361</td>\n",
              "      <td>-0.41584</td>\n",
              "      <td>0.79415</td>\n",
              "      <td>2.8406</td>\n",
              "      <td>-9.4646</td>\n",
              "      <td>-0.913570</td>\n",
              "      <td>-0.087199</td>\n",
              "      <td>-0.61351</td>\n",
              "      <td>-0.913560</td>\n",
              "      <td>-42.463000</td>\n",
              "      <td>-34.80500</td>\n",
              "      <td>1.48590</td>\n",
              "      <td>-6.6629</td>\n",
              "      <td>5.5525</td>\n",
              "      <td>-2.7536</td>\n",
              "      <td>-0.68431</td>\n",
              "      <td>-0.10678</td>\n",
              "      <td>-0.73276</td>\n",
              "      <td>13.8190</td>\n",
              "      <td>17.4000</td>\n",
              "      <td>29.7050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129021</th>\n",
              "      <td>-5.4011</td>\n",
              "      <td>-0.14952</td>\n",
              "      <td>0.46023</td>\n",
              "      <td>3.4740</td>\n",
              "      <td>-10.7230</td>\n",
              "      <td>-0.053508</td>\n",
              "      <td>-0.087199</td>\n",
              "      <td>-0.61351</td>\n",
              "      <td>-0.913560</td>\n",
              "      <td>-57.010000</td>\n",
              "      <td>-27.32000</td>\n",
              "      <td>5.02090</td>\n",
              "      <td>-7.3405</td>\n",
              "      <td>6.0766</td>\n",
              "      <td>-2.3420</td>\n",
              "      <td>-0.68431</td>\n",
              "      <td>-0.10678</td>\n",
              "      <td>-0.73276</td>\n",
              "      <td>3.4286</td>\n",
              "      <td>19.7010</td>\n",
              "      <td>31.6410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129022</th>\n",
              "      <td>-5.6132</td>\n",
              "      <td>-0.14576</td>\n",
              "      <td>0.88162</td>\n",
              "      <td>2.1789</td>\n",
              "      <td>-11.5930</td>\n",
              "      <td>-0.849510</td>\n",
              "      <td>-0.087199</td>\n",
              "      <td>-0.61351</td>\n",
              "      <td>-0.913560</td>\n",
              "      <td>-71.421000</td>\n",
              "      <td>-11.57900</td>\n",
              "      <td>10.05800</td>\n",
              "      <td>-8.1415</td>\n",
              "      <td>6.5154</td>\n",
              "      <td>-2.4555</td>\n",
              "      <td>-0.66667</td>\n",
              "      <td>-0.11499</td>\n",
              "      <td>-0.75862</td>\n",
              "      <td>-3.4091</td>\n",
              "      <td>18.1530</td>\n",
              "      <td>33.3240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129023</th>\n",
              "      <td>-6.4109</td>\n",
              "      <td>-0.16361</td>\n",
              "      <td>1.86950</td>\n",
              "      <td>2.2538</td>\n",
              "      <td>-14.3080</td>\n",
              "      <td>-0.151220</td>\n",
              "      <td>-0.129870</td>\n",
              "      <td>-0.51782</td>\n",
              "      <td>-0.972500</td>\n",
              "      <td>-80.439000</td>\n",
              "      <td>-8.00300</td>\n",
              "      <td>15.83000</td>\n",
              "      <td>-9.1205</td>\n",
              "      <td>6.6779</td>\n",
              "      <td>-3.2078</td>\n",
              "      <td>-0.66667</td>\n",
              "      <td>-0.11499</td>\n",
              "      <td>-0.75862</td>\n",
              "      <td>-9.4114</td>\n",
              "      <td>10.3870</td>\n",
              "      <td>31.1160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>233472 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        acChestX  acChestY  ...  mRightLowerArmY  mRightLowerArmZ\n",
              "0        -9.5409  -1.23920  ...          -1.2796          -2.5469\n",
              "1        -9.5641  -1.59150  ...          -1.8203          -1.8124\n",
              "2        -9.5849  -1.56120  ...          -1.9999          -1.8142\n",
              "3        -9.7097  -1.38230  ...          -1.4592          -2.1805\n",
              "4        -9.7578  -1.50300  ...          -1.0890          -1.0939\n",
              "...          ...       ...  ...              ...              ...\n",
              "129019   -5.8140  -0.21063  ...          13.5280          29.1320\n",
              "129020   -5.4361  -0.41584  ...          17.4000          29.7050\n",
              "129021   -5.4011  -0.14952  ...          19.7010          31.6410\n",
              "129022   -5.6132  -0.14576  ...          18.1530          33.3240\n",
              "129023   -6.4109  -0.16361  ...          10.3870          31.1160\n",
              "\n",
              "[233472 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8_3lMt5ZZ_t",
        "colab_type": "text"
      },
      "source": [
        "Reshaping data to fit to the convolutional model and converting to the tensor forms. Afterwards all train, validation and test datasets are loaded to the dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ovsrJDQvam5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = 21\n",
        "train_x = train_x.reshape(len(train_x), 1, window_size, num_features) \n",
        "val_x = val_x.reshape(len(val_x), 1, window_size, num_features)\n",
        "test_x = test_x.reshape(len(test_x), 1, window_size, num_features)\n",
        "\n",
        "train_y0 = np.array(train_y)\n",
        "val_y0 = np.array(val_y)\n",
        "test_y0 = np.array(test_y)\n",
        "\n",
        "train_x = torch.from_numpy(train_x).float()\n",
        "train_y = torch.from_numpy(train_y).long()\n",
        "\n",
        "val_x = torch.from_numpy(val_x).float()\n",
        "val_y = torch.from_numpy(val_y).long()\n",
        "\n",
        "test_x = torch.from_numpy(test_x).float()\n",
        "test_y = torch.from_numpy(test_y).long()\n",
        "\n",
        "training_data = data_utils.TensorDataset(train_x, train_y)\n",
        "valid_data = data_utils.TensorDataset(val_x, val_y)\n",
        "testing_data = data_utils.TensorDataset(test_x, test_y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=training_data, batch_size=400, \n",
        "                                              shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=valid_data, batch_size=400, \n",
        "                                                shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=testing_data, batch_size=400, \n",
        "                                                shuffle=False)\n",
        "\n",
        "dataloaders = [train_loader, val_loader, test_loader]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtjVreSOviLp",
        "colab_type": "code",
        "outputId": "98b21ac4-43c3-4275-c79f-4c9b6debcb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(val_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2144, 1, 125, 21])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cRnbaVJZ8sv",
        "colab_type": "text"
      },
      "source": [
        "Introducing weights to handle imbalances in data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu5xVz-QvoK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights0 = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(train_y0),\n",
        "                                                 train_y0)\n",
        "from sklearn.utils import class_weight\n",
        "class_weights1= class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(val_y0),\n",
        "                                                 val_y0)\n",
        "from sklearn.utils import class_weight\n",
        "class_weights2= class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(test_y0),\n",
        "                                                 test_y0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny0GNEQHvr3z",
        "colab_type": "code",
        "outputId": "3146fa82-f1bb-404f-f070-f5d27bf0fe18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "class_weights0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10640694, 3.12184699, 3.13458922, 3.13033027, 3.12184699,\n",
              "       3.12184699, 3.24496208, 3.19545503, 3.18221419, 3.13033027,\n",
              "       3.12184699, 3.12184699, 9.32762379])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMU3gYvGGu0w",
        "colab_type": "code",
        "outputId": "7e676055-96ce-4b50-c6bd-7c171be484ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "class_weights2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0985893 ,  2.90737834,  2.93735131,  2.90737834,  2.90737834,\n",
              "        2.90737834,  4.74871795,  5.93589744,  5.37590711,  5.81475667,\n",
              "        5.81475667,  5.81475667, 16.760181  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf93CaHgaT4u",
        "colab_type": "text"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SGO4o1RaMit",
        "colab_type": "text"
      },
      "source": [
        "Building our CNN model architecrture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJzGsLR6v1UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_conv_dim(dim_size, kernel_size, padding, stride):\n",
        "    return int((dim_size - kernel_size + 2 * padding) / stride + 1)\n",
        "\n",
        "\n",
        "class Conv2Net(nn.Module):\n",
        "    def __init__(self, num_filters_1, num_filters_2, num_filters_3,\n",
        "                 kernel_size_1, kernel_size_2, kernel_size_3, num_l1):\n",
        "        \n",
        "        super(Conv2Net, self).__init__()        \n",
        "        num_classes = 13\n",
        "        channels = train_x.shape[1]\n",
        "        height = train_x.shape[2]\n",
        "        width = train_x.shape[3]\n",
        "        stride = 1\n",
        "        padding = 0\n",
        "        max_pool_size = 2\n",
        "        max_pool_stride = 2\n",
        "\n",
        "        self.max_pool = MaxPool2d(kernel_size=max_pool_size, stride=max_pool_stride)\n",
        "        self.conv_1 = Conv2d(in_channels=channels, out_channels=num_filters_1, kernel_size=(kernel_size_1, 1), stride=stride,\n",
        "                            padding=padding)       \n",
        "        self.conv_out_height = compute_conv_dim(height, kernel_size_1, padding, stride)//max_pool_size\n",
        "        self.conv_out_width = compute_conv_dim(width, 1, padding, stride)//max_pool_size\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=num_filters_1)\n",
        "\n",
        "        self.conv_2 = Conv2d(in_channels=num_filters_1, out_channels=num_filters_2, kernel_size=(kernel_size_2, 1), stride=stride, padding=padding)\n",
        "        self.conv_out_height = compute_conv_dim(self.conv_out_height, kernel_size_2, padding, stride)//max_pool_size\n",
        "        self.conv_out_width = compute_conv_dim(self.conv_out_width, 1, padding, stride)// max_pool_size\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=num_filters_2)\n",
        "       \n",
        "        self.l1_in_features = num_filters_2 * self.conv_out_height * self.conv_out_width\n",
        "        \n",
        "        self.l_1 = Linear(in_features=self.l1_in_features, \n",
        "                          out_features=num_l1)\n",
        "        \n",
        "        self.bn4 = nn.BatchNorm1d(num_features=num_l1)\n",
        "\n",
        "        self.l_out = Linear(in_features=num_l1, \n",
        "                            out_features=num_classes)\n",
        "        \n",
        "        self.dropout = Dropout2d(p=0.5)\n",
        "\n",
        "    def forward(self, x): \n",
        "       \n",
        "        x = x.cuda()\n",
        "        x = F.relu(self.bn1(self.conv_1(x)))\n",
        "        x = self.max_pool(x)\n",
        "        x = F.relu(self.bn2(self.conv_2(x)))\n",
        "        x = self.max_pool(x)\n",
        "         \n",
        "        x = x.view(-1, self.l1_in_features)\n",
        "        \n",
        "        x = F.relu(self.bn4(self.l_1(x)))        \n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return F.log_softmax(self.l_out(x), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v4PJFBSagOI",
        "colab_type": "text"
      },
      "source": [
        "EarlyStopping class to stop the training before it overfits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFe_ssuJQ9tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        #torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        torch.save(model, 'drive/My Drive/ML final project/checkpoint50finalf.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKucwNF6aq_7",
        "colab_type": "text"
      },
      "source": [
        "# **Training and testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDuHscYXv5Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.float()\n",
        "        target = target.long()\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        weights = class_weights0\n",
        "        class_weights = torch.FloatTensor(weights).cuda()\n",
        "        loss = F.cross_entropy(output, target, weight=class_weights)\n",
        "        # loss = F.nll_loss(output, target, weight=class_weights)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            losses.append(loss.item())\n",
        "    return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikhi2U16v_H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, data_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    f1=0\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    correct = 0\n",
        "    i=0\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            i += 1\n",
        "            weights = class_weights1\n",
        "            class_weights = torch.FloatTensor(weights).cuda()\n",
        "            \n",
        "            # test_loss += F.nll_loss(output, target.to(device), weight=class_weights, reduction='sum').item() # sum up batch loss\n",
        "            test_loss += F.cross_entropy(output, target.to(device), weight=class_weights, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            pred = pred.cpu()\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            f1 += f1_score(pred, target, average='macro')\n",
        "            precision += precision_score(pred, target, average='macro')\n",
        "            recall += recall_score(pred, target, average='macro')\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "    f1 = f1 / i\n",
        "    precision = precision/i\n",
        "    recall = recall/i\n",
        "    print('\\nTest set: Average loss: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 score: {:.4f},   Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, precision, recall, f1, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    return test_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZi-VUG2wOjd",
        "colab_type": "code",
        "outputId": "3a134394-34b1-4461-bdd3-e702cebd1a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device=torch.device('cuda:0')\n",
        "model = Conv2Net(256, 128, 128, 6, 6, 4, 128).to(device)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.5, weight_decay=0.00001)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "epoch = 200\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "# initialize the early_stopping object\n",
        "early_stopping = EarlyStopping(patience=20, verbose=True)\n",
        "t0=time()\n",
        "for i in range(epoch):\n",
        "    train_loss = train(model, device, train_loader, optimizer, i)\n",
        "    train_losses.extend(train_loss)\n",
        "    val_loss = test(model, device, val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "    # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "    early_stopping(val_loss, model)\n",
        "        \n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "        \n",
        "    # load the last checkpoint with the best model\n",
        "    last_model = torch.load('drive/My Drive/ML final project/checkpoint50finalf.pt')\n",
        "    # model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "print (\"training time:\", round(time()-t0, 3), \"s\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/29951 (0%)]\tLoss: 2.670990\n",
            "Train Epoch: 0 [20000/29951 (67%)]\tLoss: 1.125937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8935, Precision: 0.0935, Recall: 0.1478, F1 score: 0.0746,   Accuracy: 2093/9337 (22%)\n",
            "\n",
            "Validation loss decreased (inf --> 0.893537).  Saving model ...\n",
            "Train Epoch: 1 [0/29951 (0%)]\tLoss: 0.820277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Conv2Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [20000/29951 (67%)]\tLoss: 0.575740\n",
            "\n",
            "Test set: Average loss: 0.5187, Precision: 0.1275, Recall: 0.1904, F1 score: 0.1112,   Accuracy: 3114/9337 (33%)\n",
            "\n",
            "Validation loss decreased (0.893537 --> 0.518700).  Saving model ...\n",
            "Train Epoch: 2 [0/29951 (0%)]\tLoss: 0.576933\n",
            "Train Epoch: 2 [20000/29951 (67%)]\tLoss: 0.446127\n",
            "\n",
            "Test set: Average loss: 0.3451, Precision: 0.1493, Recall: 0.1959, F1 score: 0.1349,   Accuracy: 4207/9337 (45%)\n",
            "\n",
            "Validation loss decreased (0.518700 --> 0.345080).  Saving model ...\n",
            "Train Epoch: 3 [0/29951 (0%)]\tLoss: 0.409020\n",
            "Train Epoch: 3 [20000/29951 (67%)]\tLoss: 0.340618\n",
            "\n",
            "Test set: Average loss: 0.2615, Precision: 0.1811, Recall: 0.2079, F1 score: 0.1643,   Accuracy: 5163/9337 (55%)\n",
            "\n",
            "Validation loss decreased (0.345080 --> 0.261485).  Saving model ...\n",
            "Train Epoch: 4 [0/29951 (0%)]\tLoss: 0.298368\n",
            "Train Epoch: 4 [20000/29951 (67%)]\tLoss: 0.404165\n",
            "\n",
            "Test set: Average loss: 0.2374, Precision: 0.2019, Recall: 0.2184, F1 score: 0.1881,   Accuracy: 5857/9337 (63%)\n",
            "\n",
            "Validation loss decreased (0.261485 --> 0.237406).  Saving model ...\n",
            "Train Epoch: 5 [0/29951 (0%)]\tLoss: 0.286787\n",
            "Train Epoch: 5 [20000/29951 (67%)]\tLoss: 0.231396\n",
            "\n",
            "Test set: Average loss: 0.1955, Precision: 0.2119, Recall: 0.2236, F1 score: 0.1982,   Accuracy: 6128/9337 (66%)\n",
            "\n",
            "Validation loss decreased (0.237406 --> 0.195546).  Saving model ...\n",
            "Train Epoch: 6 [0/29951 (0%)]\tLoss: 0.276603\n",
            "Train Epoch: 6 [20000/29951 (67%)]\tLoss: 0.310057\n",
            "\n",
            "Test set: Average loss: 0.1716, Precision: 0.2316, Recall: 0.2376, F1 score: 0.2170,   Accuracy: 6494/9337 (70%)\n",
            "\n",
            "Validation loss decreased (0.195546 --> 0.171634).  Saving model ...\n",
            "Train Epoch: 7 [0/29951 (0%)]\tLoss: 0.178730\n",
            "Train Epoch: 7 [20000/29951 (67%)]\tLoss: 0.233392\n",
            "\n",
            "Test set: Average loss: 0.1387, Precision: 0.2281, Recall: 0.2310, F1 score: 0.2126,   Accuracy: 6681/9337 (72%)\n",
            "\n",
            "Validation loss decreased (0.171634 --> 0.138724).  Saving model ...\n",
            "Train Epoch: 8 [0/29951 (0%)]\tLoss: 0.217153\n",
            "Train Epoch: 8 [20000/29951 (67%)]\tLoss: 0.181574\n",
            "\n",
            "Test set: Average loss: 0.1320, Precision: 0.2391, Recall: 0.2433, F1 score: 0.2229,   Accuracy: 6613/9337 (71%)\n",
            "\n",
            "Validation loss decreased (0.138724 --> 0.131987).  Saving model ...\n",
            "Train Epoch: 9 [0/29951 (0%)]\tLoss: 0.163842\n",
            "Train Epoch: 9 [20000/29951 (67%)]\tLoss: 0.186198\n",
            "\n",
            "Test set: Average loss: 0.1316, Precision: 0.2732, Recall: 0.2727, F1 score: 0.2567,   Accuracy: 6987/9337 (75%)\n",
            "\n",
            "Validation loss decreased (0.131987 --> 0.131611).  Saving model ...\n",
            "Train Epoch: 10 [0/29951 (0%)]\tLoss: 0.169483\n",
            "Train Epoch: 10 [20000/29951 (67%)]\tLoss: 0.198169\n",
            "\n",
            "Test set: Average loss: 0.1216, Precision: 0.3237, Recall: 0.3163, F1 score: 0.3053,   Accuracy: 7271/9337 (78%)\n",
            "\n",
            "Validation loss decreased (0.131611 --> 0.121597).  Saving model ...\n",
            "Train Epoch: 11 [0/29951 (0%)]\tLoss: 0.146006\n",
            "Train Epoch: 11 [20000/29951 (67%)]\tLoss: 0.145081\n",
            "\n",
            "Test set: Average loss: 0.1076, Precision: 0.3466, Recall: 0.3363, F1 score: 0.3297,   Accuracy: 7623/9337 (82%)\n",
            "\n",
            "Validation loss decreased (0.121597 --> 0.107609).  Saving model ...\n",
            "Train Epoch: 12 [0/29951 (0%)]\tLoss: 0.145591\n",
            "Train Epoch: 12 [20000/29951 (67%)]\tLoss: 0.138215\n",
            "\n",
            "Test set: Average loss: 0.1122, Precision: 0.2845, Recall: 0.2808, F1 score: 0.2693,   Accuracy: 7296/9337 (78%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 13 [0/29951 (0%)]\tLoss: 0.147271\n",
            "Train Epoch: 13 [20000/29951 (67%)]\tLoss: 0.131682\n",
            "\n",
            "Test set: Average loss: 0.1045, Precision: 0.3874, Recall: 0.3723, F1 score: 0.3670,   Accuracy: 7749/9337 (83%)\n",
            "\n",
            "Validation loss decreased (0.107609 --> 0.104494).  Saving model ...\n",
            "Train Epoch: 14 [0/29951 (0%)]\tLoss: 0.136176\n",
            "Train Epoch: 14 [20000/29951 (67%)]\tLoss: 0.138257\n",
            "\n",
            "Test set: Average loss: 0.1112, Precision: 0.2471, Recall: 0.2496, F1 score: 0.2325,   Accuracy: 6818/9337 (73%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 15 [0/29951 (0%)]\tLoss: 0.125531\n",
            "Train Epoch: 15 [20000/29951 (67%)]\tLoss: 0.142832\n",
            "\n",
            "Test set: Average loss: 0.0881, Precision: 0.3538, Recall: 0.3435, F1 score: 0.3337,   Accuracy: 7429/9337 (80%)\n",
            "\n",
            "Validation loss decreased (0.104494 --> 0.088138).  Saving model ...\n",
            "Train Epoch: 16 [0/29951 (0%)]\tLoss: 0.151156\n",
            "Train Epoch: 16 [20000/29951 (67%)]\tLoss: 0.134208\n",
            "\n",
            "Test set: Average loss: 0.0848, Precision: 0.3136, Recall: 0.3033, F1 score: 0.2959,   Accuracy: 7552/9337 (81%)\n",
            "\n",
            "Validation loss decreased (0.088138 --> 0.084795).  Saving model ...\n",
            "Train Epoch: 17 [0/29951 (0%)]\tLoss: 0.115737\n",
            "Train Epoch: 17 [20000/29951 (67%)]\tLoss: 0.150520\n",
            "\n",
            "Test set: Average loss: 0.0867, Precision: 0.2959, Recall: 0.2879, F1 score: 0.2773,   Accuracy: 7316/9337 (78%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 18 [0/29951 (0%)]\tLoss: 0.113231\n",
            "Train Epoch: 18 [20000/29951 (67%)]\tLoss: 0.115599\n",
            "\n",
            "Test set: Average loss: 0.0838, Precision: 0.3835, Recall: 0.3659, F1 score: 0.3600,   Accuracy: 7656/9337 (82%)\n",
            "\n",
            "Validation loss decreased (0.084795 --> 0.083809).  Saving model ...\n",
            "Train Epoch: 19 [0/29951 (0%)]\tLoss: 0.099741\n",
            "Train Epoch: 19 [20000/29951 (67%)]\tLoss: 0.116528\n",
            "\n",
            "Test set: Average loss: 0.1087, Precision: 0.3644, Recall: 0.3494, F1 score: 0.3440,   Accuracy: 7585/9337 (81%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 20 [0/29951 (0%)]\tLoss: 0.162272\n",
            "Train Epoch: 20 [20000/29951 (67%)]\tLoss: 0.130808\n",
            "\n",
            "Test set: Average loss: 0.0841, Precision: 0.3248, Recall: 0.3157, F1 score: 0.3075,   Accuracy: 7538/9337 (81%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 21 [0/29951 (0%)]\tLoss: 0.121748\n",
            "Train Epoch: 21 [20000/29951 (67%)]\tLoss: 0.118462\n",
            "\n",
            "Test set: Average loss: 0.0821, Precision: 0.4221, Recall: 0.4000, F1 score: 0.3977,   Accuracy: 7851/9337 (84%)\n",
            "\n",
            "Validation loss decreased (0.083809 --> 0.082064).  Saving model ...\n",
            "Train Epoch: 22 [0/29951 (0%)]\tLoss: 0.100335\n",
            "Train Epoch: 22 [20000/29951 (67%)]\tLoss: 0.112935\n",
            "\n",
            "Test set: Average loss: 0.0792, Precision: 0.3822, Recall: 0.3641, F1 score: 0.3601,   Accuracy: 7727/9337 (83%)\n",
            "\n",
            "Validation loss decreased (0.082064 --> 0.079230).  Saving model ...\n",
            "Train Epoch: 23 [0/29951 (0%)]\tLoss: 0.109159\n",
            "Train Epoch: 23 [20000/29951 (67%)]\tLoss: 0.094471\n",
            "\n",
            "Test set: Average loss: 0.0722, Precision: 0.3888, Recall: 0.3710, F1 score: 0.3674,   Accuracy: 7759/9337 (83%)\n",
            "\n",
            "Validation loss decreased (0.079230 --> 0.072242).  Saving model ...\n",
            "Train Epoch: 24 [0/29951 (0%)]\tLoss: 0.103599\n",
            "Train Epoch: 24 [20000/29951 (67%)]\tLoss: 0.100627\n",
            "\n",
            "Test set: Average loss: 0.0811, Precision: 0.3461, Recall: 0.3318, F1 score: 0.3256,   Accuracy: 7606/9337 (81%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 25 [0/29951 (0%)]\tLoss: 0.105952\n",
            "Train Epoch: 25 [20000/29951 (67%)]\tLoss: 0.090409\n",
            "\n",
            "Test set: Average loss: 0.0684, Precision: 0.3636, Recall: 0.3454, F1 score: 0.3416,   Accuracy: 7789/9337 (83%)\n",
            "\n",
            "Validation loss decreased (0.072242 --> 0.068406).  Saving model ...\n",
            "Train Epoch: 26 [0/29951 (0%)]\tLoss: 0.096627\n",
            "Train Epoch: 26 [20000/29951 (67%)]\tLoss: 0.103071\n",
            "\n",
            "Test set: Average loss: 0.0708, Precision: 0.3569, Recall: 0.3417, F1 score: 0.3361,   Accuracy: 7690/9337 (82%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 27 [0/29951 (0%)]\tLoss: 0.107175\n",
            "Train Epoch: 27 [20000/29951 (67%)]\tLoss: 0.110637\n",
            "\n",
            "Test set: Average loss: 0.0753, Precision: 0.4113, Recall: 0.3913, F1 score: 0.3878,   Accuracy: 7753/9337 (83%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 28 [0/29951 (0%)]\tLoss: 0.097232\n",
            "Train Epoch: 28 [20000/29951 (67%)]\tLoss: 0.108409\n",
            "\n",
            "Test set: Average loss: 0.0695, Precision: 0.4297, Recall: 0.4106, F1 score: 0.4081,   Accuracy: 7859/9337 (84%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 29 [0/29951 (0%)]\tLoss: 0.090886\n",
            "Train Epoch: 29 [20000/29951 (67%)]\tLoss: 0.102547\n",
            "\n",
            "Test set: Average loss: 0.0642, Precision: 0.4339, Recall: 0.4105, F1 score: 0.4098,   Accuracy: 7929/9337 (85%)\n",
            "\n",
            "Validation loss decreased (0.068406 --> 0.064250).  Saving model ...\n",
            "Train Epoch: 30 [0/29951 (0%)]\tLoss: 0.100501\n",
            "Train Epoch: 30 [20000/29951 (67%)]\tLoss: 0.138604\n",
            "\n",
            "Test set: Average loss: 0.0677, Precision: 0.4931, Recall: 0.4667, F1 score: 0.4671,   Accuracy: 8028/9337 (86%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 31 [0/29951 (0%)]\tLoss: 0.098189\n",
            "Train Epoch: 31 [20000/29951 (67%)]\tLoss: 0.078383\n",
            "\n",
            "Test set: Average loss: 0.0687, Precision: 0.4687, Recall: 0.4423, F1 score: 0.4419,   Accuracy: 7931/9337 (85%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 32 [0/29951 (0%)]\tLoss: 0.110576\n",
            "Train Epoch: 32 [20000/29951 (67%)]\tLoss: 0.095337\n",
            "\n",
            "Test set: Average loss: 0.0658, Precision: 0.4540, Recall: 0.4339, F1 score: 0.4314,   Accuracy: 7880/9337 (84%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 33 [0/29951 (0%)]\tLoss: 0.089345\n",
            "Train Epoch: 33 [20000/29951 (67%)]\tLoss: 0.074765\n",
            "\n",
            "Test set: Average loss: 0.0619, Precision: 0.4850, Recall: 0.4557, F1 score: 0.4580,   Accuracy: 8039/9337 (86%)\n",
            "\n",
            "Validation loss decreased (0.064250 --> 0.061879).  Saving model ...\n",
            "Train Epoch: 34 [0/29951 (0%)]\tLoss: 0.109144\n",
            "Train Epoch: 34 [20000/29951 (67%)]\tLoss: 0.089434\n",
            "\n",
            "Test set: Average loss: 0.0643, Precision: 0.4266, Recall: 0.4049, F1 score: 0.4039,   Accuracy: 7966/9337 (85%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 35 [0/29951 (0%)]\tLoss: 0.097590\n",
            "Train Epoch: 35 [20000/29951 (67%)]\tLoss: 0.093035\n",
            "\n",
            "Test set: Average loss: 0.0590, Precision: 0.6020, Recall: 0.5682, F1 score: 0.5731,   Accuracy: 8268/9337 (89%)\n",
            "\n",
            "Validation loss decreased (0.061879 --> 0.058976).  Saving model ...\n",
            "Train Epoch: 36 [0/29951 (0%)]\tLoss: 0.105107\n",
            "Train Epoch: 36 [20000/29951 (67%)]\tLoss: 0.100427\n",
            "\n",
            "Test set: Average loss: 0.0595, Precision: 0.5202, Recall: 0.4900, F1 score: 0.4928,   Accuracy: 8098/9337 (87%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 37 [0/29951 (0%)]\tLoss: 0.083791\n",
            "Train Epoch: 37 [20000/29951 (67%)]\tLoss: 0.076152\n",
            "\n",
            "Test set: Average loss: 0.0563, Precision: 0.5491, Recall: 0.5205, F1 score: 0.5230,   Accuracy: 8114/9337 (87%)\n",
            "\n",
            "Validation loss decreased (0.058976 --> 0.056313).  Saving model ...\n",
            "Train Epoch: 38 [0/29951 (0%)]\tLoss: 0.079259\n",
            "Train Epoch: 38 [20000/29951 (67%)]\tLoss: 0.085708\n",
            "\n",
            "Test set: Average loss: 0.0524, Precision: 0.4998, Recall: 0.4721, F1 score: 0.4742,   Accuracy: 8125/9337 (87%)\n",
            "\n",
            "Validation loss decreased (0.056313 --> 0.052393).  Saving model ...\n",
            "Train Epoch: 39 [0/29951 (0%)]\tLoss: 0.081930\n",
            "Train Epoch: 39 [20000/29951 (67%)]\tLoss: 0.081480\n",
            "\n",
            "Test set: Average loss: 0.0610, Precision: 0.5540, Recall: 0.5219, F1 score: 0.5273,   Accuracy: 8344/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 40 [0/29951 (0%)]\tLoss: 0.071399\n",
            "Train Epoch: 40 [20000/29951 (67%)]\tLoss: 0.062209\n",
            "\n",
            "Test set: Average loss: 0.0659, Precision: 0.5804, Recall: 0.5481, F1 score: 0.5524,   Accuracy: 8214/9337 (88%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 41 [0/29951 (0%)]\tLoss: 0.080158\n",
            "Train Epoch: 41 [20000/29951 (67%)]\tLoss: 0.104178\n",
            "\n",
            "Test set: Average loss: 0.0588, Precision: 0.4719, Recall: 0.4431, F1 score: 0.4451,   Accuracy: 8088/9337 (87%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 42 [0/29951 (0%)]\tLoss: 0.070786\n",
            "Train Epoch: 42 [20000/29951 (67%)]\tLoss: 0.081515\n",
            "\n",
            "Test set: Average loss: 0.0556, Precision: 0.4380, Recall: 0.4122, F1 score: 0.4123,   Accuracy: 8012/9337 (86%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 43 [0/29951 (0%)]\tLoss: 0.086967\n",
            "Train Epoch: 43 [20000/29951 (67%)]\tLoss: 0.071174\n",
            "\n",
            "Test set: Average loss: 0.0780, Precision: 0.5249, Recall: 0.4952, F1 score: 0.4996,   Accuracy: 8318/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 44 [0/29951 (0%)]\tLoss: 0.097469\n",
            "Train Epoch: 44 [20000/29951 (67%)]\tLoss: 0.071895\n",
            "\n",
            "Test set: Average loss: 0.0527, Precision: 0.5399, Recall: 0.5059, F1 score: 0.5102,   Accuracy: 8241/9337 (88%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 45 [0/29951 (0%)]\tLoss: 0.095353\n",
            "Train Epoch: 45 [20000/29951 (67%)]\tLoss: 0.080425\n",
            "\n",
            "Test set: Average loss: 0.0607, Precision: 0.5125, Recall: 0.4874, F1 score: 0.4888,   Accuracy: 8144/9337 (87%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 46 [0/29951 (0%)]\tLoss: 0.071465\n",
            "Train Epoch: 46 [20000/29951 (67%)]\tLoss: 0.080488\n",
            "\n",
            "Test set: Average loss: 0.0586, Precision: 0.4719, Recall: 0.4424, F1 score: 0.4441,   Accuracy: 8058/9337 (86%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 47 [0/29951 (0%)]\tLoss: 0.087685\n",
            "Train Epoch: 47 [20000/29951 (67%)]\tLoss: 0.073176\n",
            "\n",
            "Test set: Average loss: 0.0526, Precision: 0.5944, Recall: 0.5583, F1 score: 0.5640,   Accuracy: 8276/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "Train Epoch: 48 [0/29951 (0%)]\tLoss: 0.085529\n",
            "Train Epoch: 48 [20000/29951 (67%)]\tLoss: 0.074522\n",
            "\n",
            "Test set: Average loss: 0.0513, Precision: 0.6479, Recall: 0.6098, F1 score: 0.6176,   Accuracy: 8423/9337 (90%)\n",
            "\n",
            "Validation loss decreased (0.052393 --> 0.051261).  Saving model ...\n",
            "Train Epoch: 49 [0/29951 (0%)]\tLoss: 0.055062\n",
            "Train Epoch: 49 [20000/29951 (67%)]\tLoss: 0.103724\n",
            "\n",
            "Test set: Average loss: 0.0484, Precision: 0.6713, Recall: 0.6329, F1 score: 0.6405,   Accuracy: 8327/9337 (89%)\n",
            "\n",
            "Validation loss decreased (0.051261 --> 0.048439).  Saving model ...\n",
            "Train Epoch: 50 [0/29951 (0%)]\tLoss: 0.086266\n",
            "Train Epoch: 50 [20000/29951 (67%)]\tLoss: 0.061739\n",
            "\n",
            "Test set: Average loss: 0.0461, Precision: 0.5891, Recall: 0.5560, F1 score: 0.5609,   Accuracy: 8261/9337 (88%)\n",
            "\n",
            "Validation loss decreased (0.048439 --> 0.046148).  Saving model ...\n",
            "Train Epoch: 51 [0/29951 (0%)]\tLoss: 0.076212\n",
            "Train Epoch: 51 [20000/29951 (67%)]\tLoss: 0.092581\n",
            "\n",
            "Test set: Average loss: 0.0461, Precision: 0.5702, Recall: 0.5373, F1 score: 0.5421,   Accuracy: 8240/9337 (88%)\n",
            "\n",
            "Validation loss decreased (0.046148 --> 0.046105).  Saving model ...\n",
            "Train Epoch: 52 [0/29951 (0%)]\tLoss: 0.063666\n",
            "Train Epoch: 52 [20000/29951 (67%)]\tLoss: 0.068236\n",
            "\n",
            "Test set: Average loss: 0.0494, Precision: 0.6035, Recall: 0.5689, F1 score: 0.5738,   Accuracy: 8290/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 53 [0/29951 (0%)]\tLoss: 0.081678\n",
            "Train Epoch: 53 [20000/29951 (67%)]\tLoss: 0.087601\n",
            "\n",
            "Test set: Average loss: 0.0597, Precision: 0.6161, Recall: 0.5793, F1 score: 0.5857,   Accuracy: 8389/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 54 [0/29951 (0%)]\tLoss: 0.071432\n",
            "Train Epoch: 54 [20000/29951 (67%)]\tLoss: 0.063397\n",
            "\n",
            "Test set: Average loss: 0.0444, Precision: 0.5906, Recall: 0.5554, F1 score: 0.5612,   Accuracy: 8323/9337 (89%)\n",
            "\n",
            "Validation loss decreased (0.046105 --> 0.044442).  Saving model ...\n",
            "Train Epoch: 55 [0/29951 (0%)]\tLoss: 0.061063\n",
            "Train Epoch: 55 [20000/29951 (67%)]\tLoss: 0.093821\n",
            "\n",
            "Test set: Average loss: 0.1219, Precision: 0.5745, Recall: 0.5459, F1 score: 0.5492,   Accuracy: 8348/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 56 [0/29951 (0%)]\tLoss: 0.085170\n",
            "Train Epoch: 56 [20000/29951 (67%)]\tLoss: 0.095980\n",
            "\n",
            "Test set: Average loss: 0.0456, Precision: 0.5506, Recall: 0.5199, F1 score: 0.5247,   Accuracy: 8315/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 57 [0/29951 (0%)]\tLoss: 0.058180\n",
            "Train Epoch: 57 [20000/29951 (67%)]\tLoss: 0.066086\n",
            "\n",
            "Test set: Average loss: 0.0457, Precision: 0.6727, Recall: 0.6369, F1 score: 0.6452,   Accuracy: 8511/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 58 [0/29951 (0%)]\tLoss: 0.057270\n",
            "Train Epoch: 58 [20000/29951 (67%)]\tLoss: 0.066732\n",
            "\n",
            "Test set: Average loss: 0.0459, Precision: 0.5697, Recall: 0.5405, F1 score: 0.5438,   Accuracy: 8325/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 59 [0/29951 (0%)]\tLoss: 0.070833\n",
            "Train Epoch: 59 [20000/29951 (67%)]\tLoss: 0.068913\n",
            "\n",
            "Test set: Average loss: 0.0452, Precision: 0.5786, Recall: 0.5453, F1 score: 0.5508,   Accuracy: 8322/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 60 [0/29951 (0%)]\tLoss: 0.069066\n",
            "Train Epoch: 60 [20000/29951 (67%)]\tLoss: 0.055230\n",
            "\n",
            "Test set: Average loss: 0.0460, Precision: 0.5221, Recall: 0.4947, F1 score: 0.4978,   Accuracy: 8271/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 61 [0/29951 (0%)]\tLoss: 0.067359\n",
            "Train Epoch: 61 [20000/29951 (67%)]\tLoss: 0.053315\n",
            "\n",
            "Test set: Average loss: 0.0415, Precision: 0.5892, Recall: 0.5502, F1 score: 0.5582,   Accuracy: 8412/9337 (90%)\n",
            "\n",
            "Validation loss decreased (0.044442 --> 0.041519).  Saving model ...\n",
            "Train Epoch: 62 [0/29951 (0%)]\tLoss: 0.057526\n",
            "Train Epoch: 62 [20000/29951 (67%)]\tLoss: 0.057629\n",
            "\n",
            "Test set: Average loss: 0.0421, Precision: 0.5725, Recall: 0.5416, F1 score: 0.5466,   Accuracy: 8369/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 63 [0/29951 (0%)]\tLoss: 0.064240\n",
            "Train Epoch: 63 [20000/29951 (67%)]\tLoss: 0.055146\n",
            "\n",
            "Test set: Average loss: 0.0414, Precision: 0.7340, Recall: 0.6950, F1 score: 0.7047,   Accuracy: 8546/9337 (92%)\n",
            "\n",
            "Validation loss decreased (0.041519 --> 0.041426).  Saving model ...\n",
            "Train Epoch: 64 [0/29951 (0%)]\tLoss: 0.063672\n",
            "Train Epoch: 64 [20000/29951 (67%)]\tLoss: 0.049566\n",
            "\n",
            "Test set: Average loss: 0.0384, Precision: 0.6524, Recall: 0.6150, F1 score: 0.6233,   Accuracy: 8510/9337 (91%)\n",
            "\n",
            "Validation loss decreased (0.041426 --> 0.038406).  Saving model ...\n",
            "Train Epoch: 65 [0/29951 (0%)]\tLoss: 0.069247\n",
            "Train Epoch: 65 [20000/29951 (67%)]\tLoss: 0.072269\n",
            "\n",
            "Test set: Average loss: 0.0376, Precision: 0.7473, Recall: 0.7073, F1 score: 0.7172,   Accuracy: 8568/9337 (92%)\n",
            "\n",
            "Validation loss decreased (0.038406 --> 0.037629).  Saving model ...\n",
            "Train Epoch: 66 [0/29951 (0%)]\tLoss: 0.054444\n",
            "Train Epoch: 66 [20000/29951 (67%)]\tLoss: 0.049349\n",
            "\n",
            "Test set: Average loss: 0.0433, Precision: 0.6223, Recall: 0.5892, F1 score: 0.5956,   Accuracy: 8366/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 67 [0/29951 (0%)]\tLoss: 0.055303\n",
            "Train Epoch: 67 [20000/29951 (67%)]\tLoss: 0.048543\n",
            "\n",
            "Test set: Average loss: 0.0445, Precision: 0.7038, Recall: 0.6678, F1 score: 0.6759,   Accuracy: 8534/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 68 [0/29951 (0%)]\tLoss: 0.049702\n",
            "Train Epoch: 68 [20000/29951 (67%)]\tLoss: 0.104552\n",
            "\n",
            "Test set: Average loss: 0.0773, Precision: 0.5841, Recall: 0.5465, F1 score: 0.5541,   Accuracy: 8459/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 69 [0/29951 (0%)]\tLoss: 0.090850\n",
            "Train Epoch: 69 [20000/29951 (67%)]\tLoss: 0.065856\n",
            "\n",
            "Test set: Average loss: 0.0559, Precision: 0.5913, Recall: 0.5590, F1 score: 0.5653,   Accuracy: 8393/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 70 [0/29951 (0%)]\tLoss: 0.053898\n",
            "Train Epoch: 70 [20000/29951 (67%)]\tLoss: 0.077107\n",
            "\n",
            "Test set: Average loss: 0.0453, Precision: 0.5911, Recall: 0.5616, F1 score: 0.5661,   Accuracy: 8346/9337 (89%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 71 [0/29951 (0%)]\tLoss: 0.069571\n",
            "Train Epoch: 71 [20000/29951 (67%)]\tLoss: 0.055158\n",
            "\n",
            "Test set: Average loss: 0.0435, Precision: 0.5994, Recall: 0.5587, F1 score: 0.5677,   Accuracy: 8442/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 72 [0/29951 (0%)]\tLoss: 0.062456\n",
            "Train Epoch: 72 [20000/29951 (67%)]\tLoss: 0.064739\n",
            "\n",
            "Test set: Average loss: 0.0425, Precision: 0.6017, Recall: 0.5651, F1 score: 0.5714,   Accuracy: 8394/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 73 [0/29951 (0%)]\tLoss: 0.074570\n",
            "Train Epoch: 73 [20000/29951 (67%)]\tLoss: 0.077853\n",
            "\n",
            "Test set: Average loss: 0.0506, Precision: 0.7389, Recall: 0.7023, F1 score: 0.7117,   Accuracy: 8609/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 74 [0/29951 (0%)]\tLoss: 0.050485\n",
            "Train Epoch: 74 [20000/29951 (67%)]\tLoss: 0.064444\n",
            "\n",
            "Test set: Average loss: 0.0401, Precision: 0.6757, Recall: 0.6336, F1 score: 0.6426,   Accuracy: 8532/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "Train Epoch: 75 [0/29951 (0%)]\tLoss: 0.054692\n",
            "Train Epoch: 75 [20000/29951 (67%)]\tLoss: 0.060994\n",
            "\n",
            "Test set: Average loss: 0.0350, Precision: 0.7413, Recall: 0.6977, F1 score: 0.7078,   Accuracy: 8584/9337 (92%)\n",
            "\n",
            "Validation loss decreased (0.037629 --> 0.034982).  Saving model ...\n",
            "Train Epoch: 76 [0/29951 (0%)]\tLoss: 0.054659\n",
            "Train Epoch: 76 [20000/29951 (67%)]\tLoss: 0.047853\n",
            "\n",
            "Test set: Average loss: 0.0402, Precision: 0.6137, Recall: 0.5810, F1 score: 0.5874,   Accuracy: 8447/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 77 [0/29951 (0%)]\tLoss: 0.041054\n",
            "Train Epoch: 77 [20000/29951 (67%)]\tLoss: 0.055932\n",
            "\n",
            "Test set: Average loss: 0.0358, Precision: 0.7078, Recall: 0.6672, F1 score: 0.6765,   Accuracy: 8577/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 78 [0/29951 (0%)]\tLoss: 0.057353\n",
            "Train Epoch: 78 [20000/29951 (67%)]\tLoss: 0.046203\n",
            "\n",
            "Test set: Average loss: 0.0396, Precision: 0.8288, Recall: 0.7843, F1 score: 0.7959,   Accuracy: 8689/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 79 [0/29951 (0%)]\tLoss: 0.043861\n",
            "Train Epoch: 79 [20000/29951 (67%)]\tLoss: 0.073297\n",
            "\n",
            "Test set: Average loss: 0.0382, Precision: 0.6238, Recall: 0.5887, F1 score: 0.5958,   Accuracy: 8424/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 80 [0/29951 (0%)]\tLoss: 0.053397\n",
            "Train Epoch: 80 [20000/29951 (67%)]\tLoss: 0.055429\n",
            "\n",
            "Test set: Average loss: 0.0389, Precision: 0.6855, Recall: 0.6480, F1 score: 0.6576,   Accuracy: 8553/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 81 [0/29951 (0%)]\tLoss: 0.055418\n",
            "Train Epoch: 81 [20000/29951 (67%)]\tLoss: 0.056876\n",
            "\n",
            "Test set: Average loss: 0.0334, Precision: 0.8098, Recall: 0.7641, F1 score: 0.7764,   Accuracy: 8672/9337 (93%)\n",
            "\n",
            "Validation loss decreased (0.034982 --> 0.033409).  Saving model ...\n",
            "Train Epoch: 82 [0/29951 (0%)]\tLoss: 0.050098\n",
            "Train Epoch: 82 [20000/29951 (67%)]\tLoss: 0.052507\n",
            "\n",
            "Test set: Average loss: 0.0335, Precision: 0.7448, Recall: 0.7065, F1 score: 0.7154,   Accuracy: 8594/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 83 [0/29951 (0%)]\tLoss: 0.049837\n",
            "Train Epoch: 83 [20000/29951 (67%)]\tLoss: 0.053246\n",
            "\n",
            "Test set: Average loss: 0.0392, Precision: 0.6728, Recall: 0.6412, F1 score: 0.6471,   Accuracy: 8475/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 84 [0/29951 (0%)]\tLoss: 0.062179\n",
            "Train Epoch: 84 [20000/29951 (67%)]\tLoss: 0.052857\n",
            "\n",
            "Test set: Average loss: 0.0375, Precision: 0.6731, Recall: 0.6328, F1 score: 0.6428,   Accuracy: 8558/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 85 [0/29951 (0%)]\tLoss: 0.057828\n",
            "Train Epoch: 85 [20000/29951 (67%)]\tLoss: 0.058087\n",
            "\n",
            "Test set: Average loss: 0.0386, Precision: 0.7960, Recall: 0.7517, F1 score: 0.7635,   Accuracy: 8623/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 86 [0/29951 (0%)]\tLoss: 0.061938\n",
            "Train Epoch: 86 [20000/29951 (67%)]\tLoss: 0.038172\n",
            "\n",
            "Test set: Average loss: 0.0399, Precision: 0.8256, Recall: 0.7828, F1 score: 0.7944,   Accuracy: 8714/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 87 [0/29951 (0%)]\tLoss: 0.046533\n",
            "Train Epoch: 87 [20000/29951 (67%)]\tLoss: 0.048851\n",
            "\n",
            "Test set: Average loss: 0.0318, Precision: 0.7768, Recall: 0.7340, F1 score: 0.7457,   Accuracy: 8665/9337 (93%)\n",
            "\n",
            "Validation loss decreased (0.033409 --> 0.031819).  Saving model ...\n",
            "Train Epoch: 88 [0/29951 (0%)]\tLoss: 0.062040\n",
            "Train Epoch: 88 [20000/29951 (67%)]\tLoss: 0.065822\n",
            "\n",
            "Test set: Average loss: 0.0356, Precision: 0.6669, Recall: 0.6252, F1 score: 0.6339,   Accuracy: 8595/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 89 [0/29951 (0%)]\tLoss: 0.043915\n",
            "Train Epoch: 89 [20000/29951 (67%)]\tLoss: 0.053291\n",
            "\n",
            "Test set: Average loss: 0.0470, Precision: 0.6997, Recall: 0.6639, F1 score: 0.6748,   Accuracy: 8681/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 90 [0/29951 (0%)]\tLoss: 0.049396\n",
            "Train Epoch: 90 [20000/29951 (67%)]\tLoss: 0.059555\n",
            "\n",
            "Test set: Average loss: 0.0407, Precision: 0.6355, Recall: 0.6002, F1 score: 0.6079,   Accuracy: 8483/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 91 [0/29951 (0%)]\tLoss: 0.054155\n",
            "Train Epoch: 91 [20000/29951 (67%)]\tLoss: 0.053893\n",
            "\n",
            "Test set: Average loss: 0.0372, Precision: 0.6818, Recall: 0.6370, F1 score: 0.6472,   Accuracy: 8590/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 92 [0/29951 (0%)]\tLoss: 0.053678\n",
            "Train Epoch: 92 [20000/29951 (67%)]\tLoss: 0.040685\n",
            "\n",
            "Test set: Average loss: 0.0405, Precision: 0.6596, Recall: 0.6247, F1 score: 0.6321,   Accuracy: 8415/9337 (90%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 93 [0/29951 (0%)]\tLoss: 0.056226\n",
            "Train Epoch: 93 [20000/29951 (67%)]\tLoss: 0.071545\n",
            "\n",
            "Test set: Average loss: 0.0445, Precision: 0.7434, Recall: 0.7092, F1 score: 0.7183,   Accuracy: 8641/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 94 [0/29951 (0%)]\tLoss: 0.046226\n",
            "Train Epoch: 94 [20000/29951 (67%)]\tLoss: 0.070112\n",
            "\n",
            "Test set: Average loss: 0.0353, Precision: 0.7571, Recall: 0.7107, F1 score: 0.7217,   Accuracy: 8652/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 95 [0/29951 (0%)]\tLoss: 0.047841\n",
            "Train Epoch: 95 [20000/29951 (67%)]\tLoss: 0.049087\n",
            "\n",
            "Test set: Average loss: 0.0306, Precision: 0.7223, Recall: 0.6823, F1 score: 0.6918,   Accuracy: 8646/9337 (93%)\n",
            "\n",
            "Validation loss decreased (0.031819 --> 0.030567).  Saving model ...\n",
            "Train Epoch: 96 [0/29951 (0%)]\tLoss: 0.043396\n",
            "Train Epoch: 96 [20000/29951 (67%)]\tLoss: 0.059109\n",
            "\n",
            "Test set: Average loss: 0.0387, Precision: 0.6772, Recall: 0.6429, F1 score: 0.6516,   Accuracy: 8529/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 97 [0/29951 (0%)]\tLoss: 0.089557\n",
            "Train Epoch: 97 [20000/29951 (67%)]\tLoss: 0.057341\n",
            "\n",
            "Test set: Average loss: 0.0318, Precision: 0.7734, Recall: 0.7274, F1 score: 0.7391,   Accuracy: 8632/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 98 [0/29951 (0%)]\tLoss: 0.034842\n",
            "Train Epoch: 98 [20000/29951 (67%)]\tLoss: 0.042660\n",
            "\n",
            "Test set: Average loss: 0.0331, Precision: 0.7120, Recall: 0.6695, F1 score: 0.6796,   Accuracy: 8608/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 99 [0/29951 (0%)]\tLoss: 0.045578\n",
            "Train Epoch: 99 [20000/29951 (67%)]\tLoss: 0.051259\n",
            "\n",
            "Test set: Average loss: 0.0313, Precision: 0.7993, Recall: 0.7617, F1 score: 0.7721,   Accuracy: 8696/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 100 [0/29951 (0%)]\tLoss: 0.064243\n",
            "Train Epoch: 100 [20000/29951 (67%)]\tLoss: 0.048712\n",
            "\n",
            "Test set: Average loss: 0.0300, Precision: 0.7346, Recall: 0.6984, F1 score: 0.7085,   Accuracy: 8669/9337 (93%)\n",
            "\n",
            "Validation loss decreased (0.030567 --> 0.030030).  Saving model ...\n",
            "Train Epoch: 101 [0/29951 (0%)]\tLoss: 0.044316\n",
            "Train Epoch: 101 [20000/29951 (67%)]\tLoss: 0.036023\n",
            "\n",
            "Test set: Average loss: 0.0298, Precision: 0.8282, Recall: 0.7869, F1 score: 0.7985,   Accuracy: 8770/9337 (94%)\n",
            "\n",
            "Validation loss decreased (0.030030 --> 0.029781).  Saving model ...\n",
            "Train Epoch: 102 [0/29951 (0%)]\tLoss: 0.041308\n",
            "Train Epoch: 102 [20000/29951 (67%)]\tLoss: 0.032692\n",
            "\n",
            "Test set: Average loss: 0.0282, Precision: 0.7947, Recall: 0.7569, F1 score: 0.7672,   Accuracy: 8733/9337 (94%)\n",
            "\n",
            "Validation loss decreased (0.029781 --> 0.028230).  Saving model ...\n",
            "Train Epoch: 103 [0/29951 (0%)]\tLoss: 0.035938\n",
            "Train Epoch: 103 [20000/29951 (67%)]\tLoss: 0.034592\n",
            "\n",
            "Test set: Average loss: 0.0280, Precision: 0.8000, Recall: 0.7626, F1 score: 0.7723,   Accuracy: 8718/9337 (93%)\n",
            "\n",
            "Validation loss decreased (0.028230 --> 0.027994).  Saving model ...\n",
            "Train Epoch: 104 [0/29951 (0%)]\tLoss: 0.042092\n",
            "Train Epoch: 104 [20000/29951 (67%)]\tLoss: 0.044244\n",
            "\n",
            "Test set: Average loss: 0.0322, Precision: 0.7995, Recall: 0.7628, F1 score: 0.7731,   Accuracy: 8737/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 105 [0/29951 (0%)]\tLoss: 0.048660\n",
            "Train Epoch: 105 [20000/29951 (67%)]\tLoss: 0.044646\n",
            "\n",
            "Test set: Average loss: 0.0317, Precision: 0.8037, Recall: 0.7585, F1 score: 0.7718,   Accuracy: 8780/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 106 [0/29951 (0%)]\tLoss: 0.042868\n",
            "Train Epoch: 106 [20000/29951 (67%)]\tLoss: 0.041387\n",
            "\n",
            "Test set: Average loss: 0.0319, Precision: 0.7677, Recall: 0.7300, F1 score: 0.7405,   Accuracy: 8689/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 107 [0/29951 (0%)]\tLoss: 0.040045\n",
            "Train Epoch: 107 [20000/29951 (67%)]\tLoss: 0.046352\n",
            "\n",
            "Test set: Average loss: 0.0618, Precision: 0.8305, Recall: 0.7947, F1 score: 0.8054,   Accuracy: 8806/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 108 [0/29951 (0%)]\tLoss: 0.069529\n",
            "Train Epoch: 108 [20000/29951 (67%)]\tLoss: 0.094555\n",
            "\n",
            "Test set: Average loss: 0.0624, Precision: 0.8143, Recall: 0.7673, F1 score: 0.7814,   Accuracy: 8768/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 109 [0/29951 (0%)]\tLoss: 0.053886\n",
            "Train Epoch: 109 [20000/29951 (67%)]\tLoss: 0.060090\n",
            "\n",
            "Test set: Average loss: 0.0340, Precision: 0.6513, Recall: 0.6149, F1 score: 0.6237,   Accuracy: 8568/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 110 [0/29951 (0%)]\tLoss: 0.044753\n",
            "Train Epoch: 110 [20000/29951 (67%)]\tLoss: 0.039129\n",
            "\n",
            "Test set: Average loss: 0.0300, Precision: 0.7761, Recall: 0.7339, F1 score: 0.7454,   Accuracy: 8750/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 111 [0/29951 (0%)]\tLoss: 0.044300\n",
            "Train Epoch: 111 [20000/29951 (67%)]\tLoss: 0.036999\n",
            "\n",
            "Test set: Average loss: 0.0282, Precision: 0.7911, Recall: 0.7488, F1 score: 0.7599,   Accuracy: 8728/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 112 [0/29951 (0%)]\tLoss: 0.042826\n",
            "Train Epoch: 112 [20000/29951 (67%)]\tLoss: 0.048358\n",
            "\n",
            "Test set: Average loss: 0.0314, Precision: 0.8446, Recall: 0.8008, F1 score: 0.8131,   Accuracy: 8812/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "Train Epoch: 113 [0/29951 (0%)]\tLoss: 0.042557\n",
            "Train Epoch: 113 [20000/29951 (67%)]\tLoss: 0.043414\n",
            "\n",
            "Test set: Average loss: 0.0262, Precision: 0.8491, Recall: 0.8099, F1 score: 0.8211,   Accuracy: 8759/9337 (94%)\n",
            "\n",
            "Validation loss decreased (0.027994 --> 0.026214).  Saving model ...\n",
            "Train Epoch: 114 [0/29951 (0%)]\tLoss: 0.038452\n",
            "Train Epoch: 114 [20000/29951 (67%)]\tLoss: 0.036183\n",
            "\n",
            "Test set: Average loss: 0.0252, Precision: 0.8464, Recall: 0.8108, F1 score: 0.8203,   Accuracy: 8804/9337 (94%)\n",
            "\n",
            "Validation loss decreased (0.026214 --> 0.025154).  Saving model ...\n",
            "Train Epoch: 115 [0/29951 (0%)]\tLoss: 0.030985\n",
            "Train Epoch: 115 [20000/29951 (67%)]\tLoss: 0.038026\n",
            "\n",
            "Test set: Average loss: 0.0280, Precision: 0.8381, Recall: 0.8021, F1 score: 0.8121,   Accuracy: 8801/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 116 [0/29951 (0%)]\tLoss: 0.038354\n",
            "Train Epoch: 116 [20000/29951 (67%)]\tLoss: 0.036138\n",
            "\n",
            "Test set: Average loss: 0.0254, Precision: 0.8157, Recall: 0.7858, F1 score: 0.7944,   Accuracy: 8833/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 117 [0/29951 (0%)]\tLoss: 0.034598\n",
            "Train Epoch: 117 [20000/29951 (67%)]\tLoss: 0.049617\n",
            "\n",
            "Test set: Average loss: 0.0272, Precision: 0.8131, Recall: 0.7752, F1 score: 0.7854,   Accuracy: 8758/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 118 [0/29951 (0%)]\tLoss: 0.040631\n",
            "Train Epoch: 118 [20000/29951 (67%)]\tLoss: 0.044860\n",
            "\n",
            "Test set: Average loss: 0.0331, Precision: 0.7855, Recall: 0.7548, F1 score: 0.7637,   Accuracy: 8777/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 119 [0/29951 (0%)]\tLoss: 0.038042\n",
            "Train Epoch: 119 [20000/29951 (67%)]\tLoss: 0.049120\n",
            "\n",
            "Test set: Average loss: 0.0372, Precision: 0.5893, Recall: 0.5472, F1 score: 0.5559,   Accuracy: 8601/9337 (92%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 120 [0/29951 (0%)]\tLoss: 0.049504\n",
            "Train Epoch: 120 [20000/29951 (67%)]\tLoss: 0.053830\n",
            "\n",
            "Test set: Average loss: 0.0485, Precision: 0.7505, Recall: 0.7086, F1 score: 0.7195,   Accuracy: 8669/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 121 [0/29951 (0%)]\tLoss: 0.042856\n",
            "Train Epoch: 121 [20000/29951 (67%)]\tLoss: 0.068844\n",
            "\n",
            "Test set: Average loss: 0.0378, Precision: 0.5475, Recall: 0.5116, F1 score: 0.5199,   Accuracy: 8471/9337 (91%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 122 [0/29951 (0%)]\tLoss: 0.054664\n",
            "Train Epoch: 122 [20000/29951 (67%)]\tLoss: 0.042770\n",
            "\n",
            "Test set: Average loss: 0.0305, Precision: 0.8419, Recall: 0.7991, F1 score: 0.8112,   Accuracy: 8731/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 123 [0/29951 (0%)]\tLoss: 0.043384\n",
            "Train Epoch: 123 [20000/29951 (67%)]\tLoss: 0.039515\n",
            "\n",
            "Test set: Average loss: 0.0281, Precision: 0.8032, Recall: 0.7648, F1 score: 0.7746,   Accuracy: 8667/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "Train Epoch: 124 [0/29951 (0%)]\tLoss: 0.036324\n",
            "Train Epoch: 124 [20000/29951 (67%)]\tLoss: 0.043974\n",
            "\n",
            "Test set: Average loss: 0.0248, Precision: 0.8263, Recall: 0.7889, F1 score: 0.7990,   Accuracy: 8763/9337 (94%)\n",
            "\n",
            "Validation loss decreased (0.025154 --> 0.024792).  Saving model ...\n",
            "Train Epoch: 125 [0/29951 (0%)]\tLoss: 0.048427\n",
            "Train Epoch: 125 [20000/29951 (67%)]\tLoss: 0.031046\n",
            "\n",
            "Test set: Average loss: 0.0248, Precision: 0.8603, Recall: 0.8269, F1 score: 0.8378,   Accuracy: 8870/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 126 [0/29951 (0%)]\tLoss: 0.040667\n",
            "Train Epoch: 126 [20000/29951 (67%)]\tLoss: 0.035910\n",
            "\n",
            "Test set: Average loss: 0.0268, Precision: 0.8761, Recall: 0.8393, F1 score: 0.8495,   Accuracy: 8869/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 127 [0/29951 (0%)]\tLoss: 0.038825\n",
            "Train Epoch: 127 [20000/29951 (67%)]\tLoss: 0.026716\n",
            "\n",
            "Test set: Average loss: 0.0227, Precision: 0.8775, Recall: 0.8393, F1 score: 0.8496,   Accuracy: 8844/9337 (95%)\n",
            "\n",
            "Validation loss decreased (0.024792 --> 0.022705).  Saving model ...\n",
            "Train Epoch: 128 [0/29951 (0%)]\tLoss: 0.033777\n",
            "Train Epoch: 128 [20000/29951 (67%)]\tLoss: 0.023659\n",
            "\n",
            "Test set: Average loss: 0.0248, Precision: 0.8594, Recall: 0.8258, F1 score: 0.8347,   Accuracy: 8798/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 129 [0/29951 (0%)]\tLoss: 0.039285\n",
            "Train Epoch: 129 [20000/29951 (67%)]\tLoss: 0.027099\n",
            "\n",
            "Test set: Average loss: 0.0244, Precision: 0.8427, Recall: 0.8082, F1 score: 0.8178,   Accuracy: 8853/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 130 [0/29951 (0%)]\tLoss: 0.033087\n",
            "Train Epoch: 130 [20000/29951 (67%)]\tLoss: 0.042497\n",
            "\n",
            "Test set: Average loss: 0.0245, Precision: 0.8398, Recall: 0.8030, F1 score: 0.8133,   Accuracy: 8782/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 131 [0/29951 (0%)]\tLoss: 0.038093\n",
            "Train Epoch: 131 [20000/29951 (67%)]\tLoss: 0.043134\n",
            "\n",
            "Test set: Average loss: 0.0232, Precision: 0.9007, Recall: 0.8651, F1 score: 0.8750,   Accuracy: 8898/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 132 [0/29951 (0%)]\tLoss: 0.022199\n",
            "Train Epoch: 132 [20000/29951 (67%)]\tLoss: 0.039810\n",
            "\n",
            "Test set: Average loss: 0.0254, Precision: 0.9060, Recall: 0.8760, F1 score: 0.8851,   Accuracy: 8923/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 133 [0/29951 (0%)]\tLoss: 0.043773\n",
            "Train Epoch: 133 [20000/29951 (67%)]\tLoss: 0.034470\n",
            "\n",
            "Test set: Average loss: 0.0242, Precision: 0.8393, Recall: 0.8065, F1 score: 0.8146,   Accuracy: 8785/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 134 [0/29951 (0%)]\tLoss: 0.036279\n",
            "Train Epoch: 134 [20000/29951 (67%)]\tLoss: 0.035543\n",
            "\n",
            "Test set: Average loss: 0.0222, Precision: 0.9022, Recall: 0.8663, F1 score: 0.8762,   Accuracy: 8866/9337 (95%)\n",
            "\n",
            "Validation loss decreased (0.022705 --> 0.022226).  Saving model ...\n",
            "Train Epoch: 135 [0/29951 (0%)]\tLoss: 0.035825\n",
            "Train Epoch: 135 [20000/29951 (67%)]\tLoss: 0.020895\n",
            "\n",
            "Test set: Average loss: 0.0271, Precision: 0.8309, Recall: 0.7967, F1 score: 0.8057,   Accuracy: 8832/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 136 [0/29951 (0%)]\tLoss: 0.028065\n",
            "Train Epoch: 136 [20000/29951 (67%)]\tLoss: 0.042580\n",
            "\n",
            "Test set: Average loss: 0.0290, Precision: 0.8651, Recall: 0.8346, F1 score: 0.8435,   Accuracy: 8916/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 137 [0/29951 (0%)]\tLoss: 0.044766\n",
            "Train Epoch: 137 [20000/29951 (67%)]\tLoss: 0.034320\n",
            "\n",
            "Test set: Average loss: 0.0241, Precision: 0.8156, Recall: 0.7771, F1 score: 0.7867,   Accuracy: 8838/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 138 [0/29951 (0%)]\tLoss: 0.047612\n",
            "Train Epoch: 138 [20000/29951 (67%)]\tLoss: 0.046517\n",
            "\n",
            "Test set: Average loss: 0.0252, Precision: 0.8413, Recall: 0.8074, F1 score: 0.8168,   Accuracy: 8847/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 139 [0/29951 (0%)]\tLoss: 0.039063\n",
            "Train Epoch: 139 [20000/29951 (67%)]\tLoss: 0.034911\n",
            "\n",
            "Test set: Average loss: 0.0280, Precision: 0.8492, Recall: 0.8152, F1 score: 0.8229,   Accuracy: 8746/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 140 [0/29951 (0%)]\tLoss: 0.032454\n",
            "Train Epoch: 140 [20000/29951 (67%)]\tLoss: 0.064139\n",
            "\n",
            "Test set: Average loss: 0.0284, Precision: 0.7920, Recall: 0.7526, F1 score: 0.7626,   Accuracy: 8749/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 141 [0/29951 (0%)]\tLoss: 0.041692\n",
            "Train Epoch: 141 [20000/29951 (67%)]\tLoss: 0.034628\n",
            "\n",
            "Test set: Average loss: 0.0260, Precision: 0.7390, Recall: 0.7070, F1 score: 0.7151,   Accuracy: 8837/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 142 [0/29951 (0%)]\tLoss: 0.048316\n",
            "Train Epoch: 142 [20000/29951 (67%)]\tLoss: 0.039851\n",
            "\n",
            "Test set: Average loss: 0.0233, Precision: 0.8355, Recall: 0.7982, F1 score: 0.8092,   Accuracy: 8841/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 143 [0/29951 (0%)]\tLoss: 0.049687\n",
            "Train Epoch: 143 [20000/29951 (67%)]\tLoss: 0.028456\n",
            "\n",
            "Test set: Average loss: 0.0228, Precision: 0.9058, Recall: 0.8775, F1 score: 0.8853,   Accuracy: 8865/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "Train Epoch: 144 [0/29951 (0%)]\tLoss: 0.046502\n",
            "Train Epoch: 144 [20000/29951 (67%)]\tLoss: 0.039395\n",
            "\n",
            "Test set: Average loss: 0.0413, Precision: 0.9359, Recall: 0.9009, F1 score: 0.9121,   Accuracy: 8936/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 10 out of 20\n",
            "Train Epoch: 145 [0/29951 (0%)]\tLoss: 0.033598\n",
            "Train Epoch: 145 [20000/29951 (67%)]\tLoss: 0.042423\n",
            "\n",
            "Test set: Average loss: 0.0240, Precision: 0.7828, Recall: 0.7466, F1 score: 0.7557,   Accuracy: 8817/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 11 out of 20\n",
            "Train Epoch: 146 [0/29951 (0%)]\tLoss: 0.031800\n",
            "Train Epoch: 146 [20000/29951 (67%)]\tLoss: 0.033328\n",
            "\n",
            "Test set: Average loss: 0.0339, Precision: 0.8024, Recall: 0.7750, F1 score: 0.7826,   Accuracy: 8820/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 12 out of 20\n",
            "Train Epoch: 147 [0/29951 (0%)]\tLoss: 0.039095\n",
            "Train Epoch: 147 [20000/29951 (67%)]\tLoss: 0.055259\n",
            "\n",
            "Test set: Average loss: 0.0218, Precision: 0.8757, Recall: 0.8398, F1 score: 0.8500,   Accuracy: 8884/9337 (95%)\n",
            "\n",
            "Validation loss decreased (0.022226 --> 0.021769).  Saving model ...\n",
            "Train Epoch: 148 [0/29951 (0%)]\tLoss: 0.030342\n",
            "Train Epoch: 148 [20000/29951 (67%)]\tLoss: 0.038467\n",
            "\n",
            "Test set: Average loss: 0.0220, Precision: 0.8036, Recall: 0.7727, F1 score: 0.7808,   Accuracy: 8824/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 149 [0/29951 (0%)]\tLoss: 0.029447\n",
            "Train Epoch: 149 [20000/29951 (67%)]\tLoss: 0.047195\n",
            "\n",
            "Test set: Average loss: 0.0382, Precision: 0.7740, Recall: 0.7297, F1 score: 0.7417,   Accuracy: 8786/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 150 [0/29951 (0%)]\tLoss: 0.042950\n",
            "Train Epoch: 150 [20000/29951 (67%)]\tLoss: 0.034233\n",
            "\n",
            "Test set: Average loss: 0.0251, Precision: 0.8300, Recall: 0.7948, F1 score: 0.8059,   Accuracy: 8897/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 151 [0/29951 (0%)]\tLoss: 0.041150\n",
            "Train Epoch: 151 [20000/29951 (67%)]\tLoss: 0.051131\n",
            "\n",
            "Test set: Average loss: 0.0396, Precision: 0.7973, Recall: 0.7535, F1 score: 0.7657,   Accuracy: 8752/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 152 [0/29951 (0%)]\tLoss: 0.047351\n",
            "Train Epoch: 152 [20000/29951 (67%)]\tLoss: 0.046254\n",
            "\n",
            "Test set: Average loss: 0.0259, Precision: 0.8489, Recall: 0.8135, F1 score: 0.8247,   Accuracy: 8828/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 153 [0/29951 (0%)]\tLoss: 0.041685\n",
            "Train Epoch: 153 [20000/29951 (67%)]\tLoss: 0.032872\n",
            "\n",
            "Test set: Average loss: 0.0319, Precision: 0.8306, Recall: 0.7876, F1 score: 0.8015,   Accuracy: 8851/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 154 [0/29951 (0%)]\tLoss: 0.057748\n",
            "Train Epoch: 154 [20000/29951 (67%)]\tLoss: 0.060832\n",
            "\n",
            "Test set: Average loss: 0.2624, Precision: 0.7259, Recall: 0.7021, F1 score: 0.7041,   Accuracy: 8670/9337 (93%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 155 [0/29951 (0%)]\tLoss: 0.037725\n",
            "Train Epoch: 155 [20000/29951 (67%)]\tLoss: 0.034374\n",
            "\n",
            "Test set: Average loss: 0.0746, Precision: 0.8434, Recall: 0.8067, F1 score: 0.8171,   Accuracy: 8826/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 156 [0/29951 (0%)]\tLoss: 0.031900\n",
            "Train Epoch: 156 [20000/29951 (67%)]\tLoss: 0.032888\n",
            "\n",
            "Test set: Average loss: 0.0244, Precision: 0.8412, Recall: 0.8033, F1 score: 0.8132,   Accuracy: 8813/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "Train Epoch: 157 [0/29951 (0%)]\tLoss: 0.029639\n",
            "Train Epoch: 157 [20000/29951 (67%)]\tLoss: 0.032274\n",
            "\n",
            "Test set: Average loss: 0.0304, Precision: 0.8191, Recall: 0.7835, F1 score: 0.7949,   Accuracy: 8832/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 10 out of 20\n",
            "Train Epoch: 158 [0/29951 (0%)]\tLoss: 0.057957\n",
            "Train Epoch: 158 [20000/29951 (67%)]\tLoss: 0.039391\n",
            "\n",
            "Test set: Average loss: 0.0240, Precision: 0.8324, Recall: 0.7994, F1 score: 0.8086,   Accuracy: 8834/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 11 out of 20\n",
            "Train Epoch: 159 [0/29951 (0%)]\tLoss: 0.026751\n",
            "Train Epoch: 159 [20000/29951 (67%)]\tLoss: 0.027745\n",
            "\n",
            "Test set: Average loss: 0.0217, Precision: 0.8768, Recall: 0.8423, F1 score: 0.8525,   Accuracy: 8876/9337 (95%)\n",
            "\n",
            "Validation loss decreased (0.021769 --> 0.021694).  Saving model ...\n",
            "Train Epoch: 160 [0/29951 (0%)]\tLoss: 0.028650\n",
            "Train Epoch: 160 [20000/29951 (67%)]\tLoss: 0.027891\n",
            "\n",
            "Test set: Average loss: 0.0229, Precision: 0.8455, Recall: 0.8090, F1 score: 0.8183,   Accuracy: 8906/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 161 [0/29951 (0%)]\tLoss: 0.024790\n",
            "Train Epoch: 161 [20000/29951 (67%)]\tLoss: 0.036623\n",
            "\n",
            "Test set: Average loss: 0.0206, Precision: 0.8769, Recall: 0.8463, F1 score: 0.8547,   Accuracy: 8891/9337 (95%)\n",
            "\n",
            "Validation loss decreased (0.021694 --> 0.020644).  Saving model ...\n",
            "Train Epoch: 162 [0/29951 (0%)]\tLoss: 0.026847\n",
            "Train Epoch: 162 [20000/29951 (67%)]\tLoss: 0.039626\n",
            "\n",
            "Test set: Average loss: 0.0228, Precision: 0.8915, Recall: 0.8648, F1 score: 0.8722,   Accuracy: 8926/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 163 [0/29951 (0%)]\tLoss: 0.024959\n",
            "Train Epoch: 163 [20000/29951 (67%)]\tLoss: 0.029922\n",
            "\n",
            "Test set: Average loss: 0.0223, Precision: 0.8778, Recall: 0.8455, F1 score: 0.8554,   Accuracy: 8904/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 164 [0/29951 (0%)]\tLoss: 0.045457\n",
            "Train Epoch: 164 [20000/29951 (67%)]\tLoss: 0.027758\n",
            "\n",
            "Test set: Average loss: 0.0203, Precision: 0.8906, Recall: 0.8563, F1 score: 0.8662,   Accuracy: 8922/9337 (96%)\n",
            "\n",
            "Validation loss decreased (0.020644 --> 0.020255).  Saving model ...\n",
            "Train Epoch: 165 [0/29951 (0%)]\tLoss: 0.036433\n",
            "Train Epoch: 165 [20000/29951 (67%)]\tLoss: 0.018788\n",
            "\n",
            "Test set: Average loss: 0.0197, Precision: 0.8927, Recall: 0.8715, F1 score: 0.8768,   Accuracy: 8946/9337 (96%)\n",
            "\n",
            "Validation loss decreased (0.020255 --> 0.019737).  Saving model ...\n",
            "Train Epoch: 166 [0/29951 (0%)]\tLoss: 0.025291\n",
            "Train Epoch: 166 [20000/29951 (67%)]\tLoss: 0.032292\n",
            "\n",
            "Test set: Average loss: 0.0208, Precision: 0.9368, Recall: 0.9045, F1 score: 0.9139,   Accuracy: 8931/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 167 [0/29951 (0%)]\tLoss: 0.026805\n",
            "Train Epoch: 167 [20000/29951 (67%)]\tLoss: 0.027937\n",
            "\n",
            "Test set: Average loss: 0.0215, Precision: 0.9398, Recall: 0.9159, F1 score: 0.9226,   Accuracy: 8992/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 168 [0/29951 (0%)]\tLoss: 0.026501\n",
            "Train Epoch: 168 [20000/29951 (67%)]\tLoss: 0.019456\n",
            "\n",
            "Test set: Average loss: 0.0197, Precision: 0.9121, Recall: 0.8864, F1 score: 0.8942,   Accuracy: 8974/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 169 [0/29951 (0%)]\tLoss: 0.026456\n",
            "Train Epoch: 169 [20000/29951 (67%)]\tLoss: 0.031420\n",
            "\n",
            "Test set: Average loss: 0.0191, Precision: 0.8885, Recall: 0.8682, F1 score: 0.8735,   Accuracy: 8963/9337 (96%)\n",
            "\n",
            "Validation loss decreased (0.019737 --> 0.019142).  Saving model ...\n",
            "Train Epoch: 170 [0/29951 (0%)]\tLoss: 0.025946\n",
            "Train Epoch: 170 [20000/29951 (67%)]\tLoss: 0.042466\n",
            "\n",
            "Test set: Average loss: 0.0224, Precision: 0.9398, Recall: 0.9187, F1 score: 0.9244,   Accuracy: 8989/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 171 [0/29951 (0%)]\tLoss: 0.027525\n",
            "Train Epoch: 171 [20000/29951 (67%)]\tLoss: 0.024290\n",
            "\n",
            "Test set: Average loss: 0.0216, Precision: 0.8950, Recall: 0.8730, F1 score: 0.8782,   Accuracy: 8910/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 172 [0/29951 (0%)]\tLoss: 0.025251\n",
            "Train Epoch: 172 [20000/29951 (67%)]\tLoss: 0.021449\n",
            "\n",
            "Test set: Average loss: 0.0213, Precision: 0.8605, Recall: 0.8384, F1 score: 0.8435,   Accuracy: 8913/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 173 [0/29951 (0%)]\tLoss: 0.027000\n",
            "Train Epoch: 173 [20000/29951 (67%)]\tLoss: 0.022622\n",
            "\n",
            "Test set: Average loss: 0.0189, Precision: 0.9383, Recall: 0.9101, F1 score: 0.9183,   Accuracy: 8971/9337 (96%)\n",
            "\n",
            "Validation loss decreased (0.019142 --> 0.018941).  Saving model ...\n",
            "Train Epoch: 174 [0/29951 (0%)]\tLoss: 0.022682\n",
            "Train Epoch: 174 [20000/29951 (67%)]\tLoss: 0.032580\n",
            "\n",
            "Test set: Average loss: 0.0208, Precision: 0.9137, Recall: 0.8842, F1 score: 0.8927,   Accuracy: 8948/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 175 [0/29951 (0%)]\tLoss: 0.025945\n",
            "Train Epoch: 175 [20000/29951 (67%)]\tLoss: 0.021828\n",
            "\n",
            "Test set: Average loss: 0.0186, Precision: 0.9171, Recall: 0.8902, F1 score: 0.8978,   Accuracy: 8961/9337 (96%)\n",
            "\n",
            "Validation loss decreased (0.018941 --> 0.018613).  Saving model ...\n",
            "Train Epoch: 176 [0/29951 (0%)]\tLoss: 0.038314\n",
            "Train Epoch: 176 [20000/29951 (67%)]\tLoss: 0.030765\n",
            "\n",
            "Test set: Average loss: 0.0208, Precision: 0.9052, Recall: 0.8809, F1 score: 0.8876,   Accuracy: 8918/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 177 [0/29951 (0%)]\tLoss: 0.031784\n",
            "Train Epoch: 177 [20000/29951 (67%)]\tLoss: 0.046184\n",
            "\n",
            "Test set: Average loss: 0.0831, Precision: 0.7263, Recall: 0.6886, F1 score: 0.6999,   Accuracy: 8787/9337 (94%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 178 [0/29951 (0%)]\tLoss: 0.038125\n",
            "Train Epoch: 178 [20000/29951 (67%)]\tLoss: 0.052550\n",
            "\n",
            "Test set: Average loss: 0.0369, Precision: 0.8294, Recall: 0.7911, F1 score: 0.8030,   Accuracy: 8886/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 179 [0/29951 (0%)]\tLoss: 0.040089\n",
            "Train Epoch: 179 [20000/29951 (67%)]\tLoss: 0.039321\n",
            "\n",
            "Test set: Average loss: 0.0292, Precision: 0.8748, Recall: 0.8416, F1 score: 0.8515,   Accuracy: 8854/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 180 [0/29951 (0%)]\tLoss: 0.043999\n",
            "Train Epoch: 180 [20000/29951 (67%)]\tLoss: 0.047048\n",
            "\n",
            "Test set: Average loss: 0.0213, Precision: 0.8907, Recall: 0.8545, F1 score: 0.8658,   Accuracy: 8904/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 181 [0/29951 (0%)]\tLoss: 0.028656\n",
            "Train Epoch: 181 [20000/29951 (67%)]\tLoss: 0.032994\n",
            "\n",
            "Test set: Average loss: 0.0269, Precision: 0.8551, Recall: 0.8227, F1 score: 0.8335,   Accuracy: 8932/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 182 [0/29951 (0%)]\tLoss: 0.031023\n",
            "Train Epoch: 182 [20000/29951 (67%)]\tLoss: 0.025151\n",
            "\n",
            "Test set: Average loss: 0.0219, Precision: 0.8737, Recall: 0.8445, F1 score: 0.8540,   Accuracy: 8980/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 183 [0/29951 (0%)]\tLoss: 0.032176\n",
            "Train Epoch: 183 [20000/29951 (67%)]\tLoss: 0.032343\n",
            "\n",
            "Test set: Average loss: 0.0187, Precision: 0.9010, Recall: 0.8723, F1 score: 0.8810,   Accuracy: 8985/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 184 [0/29951 (0%)]\tLoss: 0.032950\n",
            "Train Epoch: 184 [20000/29951 (67%)]\tLoss: 0.026946\n",
            "\n",
            "Test set: Average loss: 0.0198, Precision: 0.8828, Recall: 0.8495, F1 score: 0.8596,   Accuracy: 8953/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "Train Epoch: 185 [0/29951 (0%)]\tLoss: 0.028582\n",
            "Train Epoch: 185 [20000/29951 (67%)]\tLoss: 0.023516\n",
            "\n",
            "Test set: Average loss: 0.0191, Precision: 0.8574, Recall: 0.8254, F1 score: 0.8346,   Accuracy: 8917/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 10 out of 20\n",
            "Train Epoch: 186 [0/29951 (0%)]\tLoss: 0.034711\n",
            "Train Epoch: 186 [20000/29951 (67%)]\tLoss: 0.025087\n",
            "\n",
            "Test set: Average loss: 0.0207, Precision: 0.8666, Recall: 0.8342, F1 score: 0.8430,   Accuracy: 8902/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 11 out of 20\n",
            "Train Epoch: 187 [0/29951 (0%)]\tLoss: 0.026602\n",
            "Train Epoch: 187 [20000/29951 (67%)]\tLoss: 0.037518\n",
            "\n",
            "Test set: Average loss: 0.0200, Precision: 0.8867, Recall: 0.8596, F1 score: 0.8675,   Accuracy: 8946/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 12 out of 20\n",
            "Train Epoch: 188 [0/29951 (0%)]\tLoss: 0.040197\n",
            "Train Epoch: 188 [20000/29951 (67%)]\tLoss: 0.032267\n",
            "\n",
            "Test set: Average loss: 0.1048, Precision: 0.8732, Recall: 0.8447, F1 score: 0.8513,   Accuracy: 8915/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 13 out of 20\n",
            "Train Epoch: 189 [0/29951 (0%)]\tLoss: 0.028856\n",
            "Train Epoch: 189 [20000/29951 (67%)]\tLoss: 0.028265\n",
            "\n",
            "Test set: Average loss: 0.0196, Precision: 0.8861, Recall: 0.8598, F1 score: 0.8671,   Accuracy: 8934/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 14 out of 20\n",
            "Train Epoch: 190 [0/29951 (0%)]\tLoss: 0.047472\n",
            "Train Epoch: 190 [20000/29951 (67%)]\tLoss: 0.025873\n",
            "\n",
            "Test set: Average loss: 0.0181, Precision: 0.9224, Recall: 0.8980, F1 score: 0.9052,   Accuracy: 8975/9337 (96%)\n",
            "\n",
            "Validation loss decreased (0.018613 --> 0.018077).  Saving model ...\n",
            "Train Epoch: 191 [0/29951 (0%)]\tLoss: 0.027739\n",
            "Train Epoch: 191 [20000/29951 (67%)]\tLoss: 0.029421\n",
            "\n",
            "Test set: Average loss: 0.0181, Precision: 0.9154, Recall: 0.8893, F1 score: 0.8968,   Accuracy: 8963/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 1 out of 20\n",
            "Train Epoch: 192 [0/29951 (0%)]\tLoss: 0.023321\n",
            "Train Epoch: 192 [20000/29951 (67%)]\tLoss: 0.017046\n",
            "\n",
            "Test set: Average loss: 0.0276, Precision: 0.9170, Recall: 0.8901, F1 score: 0.8992,   Accuracy: 9000/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 2 out of 20\n",
            "Train Epoch: 193 [0/29951 (0%)]\tLoss: 0.027148\n",
            "Train Epoch: 193 [20000/29951 (67%)]\tLoss: 0.034342\n",
            "\n",
            "Test set: Average loss: 0.2518, Precision: 0.9079, Recall: 0.8760, F1 score: 0.8873,   Accuracy: 8829/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 3 out of 20\n",
            "Train Epoch: 194 [0/29951 (0%)]\tLoss: 0.034594\n",
            "Train Epoch: 194 [20000/29951 (67%)]\tLoss: 0.030434\n",
            "\n",
            "Test set: Average loss: 0.0204, Precision: 0.8773, Recall: 0.8427, F1 score: 0.8536,   Accuracy: 8901/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 4 out of 20\n",
            "Train Epoch: 195 [0/29951 (0%)]\tLoss: 0.037646\n",
            "Train Epoch: 195 [20000/29951 (67%)]\tLoss: 0.036580\n",
            "\n",
            "Test set: Average loss: 0.0215, Precision: 0.9181, Recall: 0.8896, F1 score: 0.8984,   Accuracy: 8961/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 5 out of 20\n",
            "Train Epoch: 196 [0/29951 (0%)]\tLoss: 0.022336\n",
            "Train Epoch: 196 [20000/29951 (67%)]\tLoss: 0.030524\n",
            "\n",
            "Test set: Average loss: 0.0184, Precision: 0.8965, Recall: 0.8723, F1 score: 0.8791,   Accuracy: 8955/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 6 out of 20\n",
            "Train Epoch: 197 [0/29951 (0%)]\tLoss: 0.025890\n",
            "Train Epoch: 197 [20000/29951 (67%)]\tLoss: 0.019505\n",
            "\n",
            "Test set: Average loss: 0.0202, Precision: 0.9191, Recall: 0.8909, F1 score: 0.9000,   Accuracy: 8987/9337 (96%)\n",
            "\n",
            "EarlyStopping counter: 7 out of 20\n",
            "Train Epoch: 198 [0/29951 (0%)]\tLoss: 0.027393\n",
            "Train Epoch: 198 [20000/29951 (67%)]\tLoss: 0.020052\n",
            "\n",
            "Test set: Average loss: 0.0255, Precision: 0.8421, Recall: 0.8199, F1 score: 0.8250,   Accuracy: 8899/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 8 out of 20\n",
            "Train Epoch: 199 [0/29951 (0%)]\tLoss: 0.038023\n",
            "Train Epoch: 199 [20000/29951 (67%)]\tLoss: 0.033731\n",
            "\n",
            "Test set: Average loss: 0.0213, Precision: 0.8211, Recall: 0.7835, F1 score: 0.7949,   Accuracy: 8908/9337 (95%)\n",
            "\n",
            "EarlyStopping counter: 9 out of 20\n",
            "training time: 929.802 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVahxv-Y5rUk",
        "colab_type": "code",
        "outputId": "eef9da4f-f7c9-4d7f-ab2f-ed1fb739f242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(epoch)\n",
        "print(train_losses)\n",
        "print(val_losses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "[2.641268491744995, 1.121956706047058, 0.8708373308181763, 0.5824713110923767, 0.5959499478340149, 0.4502660632133484, 0.4198485314846039, 0.2767498195171356, 0.3035792410373688, 0.3107570707798004, 0.25615787506103516, 0.3101062774658203, 0.1994459182024002, 0.23893865942955017, 0.21491293609142303, 0.2052297294139862, 0.18573959171772003, 0.2103005051612854, 0.19354230165481567, 0.2324867695569992, 0.1991918832063675, 0.167996346950531, 0.16560854017734528, 0.1912914663553238, 0.1823722869157791, 0.13787539303302765, 0.15155968070030212, 0.16393277049064636, 0.1123584732413292, 0.13945819437503815, 0.12391341477632523, 0.10491505265235901, 0.12978124618530273, 0.11956332623958588, 0.12778010964393616, 0.14542293548583984, 0.14704039692878723, 0.1342046707868576, 0.12072135508060455, 0.13611526787281036, 0.12990233302116394, 0.11038235574960709, 0.11787528544664383, 0.09914693236351013, 0.11674658209085464, 0.11836022883653641, 0.11923998594284058, 0.10510315001010895, 0.10785993933677673, 0.12809312343597412, 0.10012198239564896, 0.1276688575744629, 0.11391593515872955, 0.11585675179958344, 0.08520396053791046, 0.12521950900554657, 0.09451978653669357, 0.09522757679224014, 0.08841071277856827, 0.09379027783870697, 0.1247149109840393, 0.11066947132349014, 0.10623380541801453, 0.08220662921667099, 0.09535789489746094, 0.09817147254943848, 0.06908667832612991, 0.10654190927743912, 0.08327322453260422, 0.09782559424638748, 0.10240333527326584, 0.06821669638156891, 0.079276904463768, 0.07886052876710892, 0.09464371204376221, 0.08578353375196457, 0.07526899874210358, 0.08555512875318527, 0.07873354852199554, 0.09106004983186722, 0.07982353121042252, 0.07296086847782135, 0.06186432018876076, 0.07814444601535797, 0.06068992242217064, 0.08285214751958847, 0.07368062436580658, 0.07572939246892929, 0.08095959573984146, 0.0683937817811966, 0.07579207420349121, 0.07740354537963867, 0.06518495082855225, 0.08867254108190536, 0.05813252925872803, 0.0797479972243309, 0.06632690876722336, 0.05178435519337654, 0.0660371333360672, 0.16516272723674774, 0.07530435174703598, 0.09420744329690933, 0.09593173861503601, 0.11593952029943466, 0.09711837768554688, 0.068463034927845, 0.06985904276371002, 0.08597950637340546, 0.07745712995529175, 0.07009740173816681, 0.07983291149139404, 0.07019464671611786, 0.06809871643781662, 0.06680093705654144, 0.079865962266922, 0.05854625254869461, 0.051644500344991684, 0.09534680098295212, 0.05100347846746445, 0.04142359271645546, 0.05628485232591629, 0.05257895588874817, 0.0542878694832325, 0.04567801579833031, 0.04935656115412712, 0.061827391386032104, 0.06039859727025032, 0.06620855629444122, 0.058719296008348465, 0.06152825802564621, 0.057802751660346985, 0.05603284388780594, 0.0745839849114418, 0.06575654447078705, 0.04740866273641586, 0.0622248500585556, 0.056096892803907394, 0.08857536315917969, 0.048073749989271164, 0.05890938267111778, 0.06435264647006989, 0.04834965616464615, 0.08047162741422653, 0.06252159178256989, 0.0454249307513237, 0.05358564481139183, 0.053254708647727966, 0.05455787479877472, 0.044209446758031845, 0.03866983577609062, 0.05258234217762947, 0.05619049444794655, 0.08400046825408936, 0.17741456627845764, 0.10694779455661774, 0.06167561933398247, 0.07173796743154526, 0.07326429337263107, 0.06626957654953003, 0.05966554954648018, 0.05461737886071205, 0.05266037955880165, 0.059525128453969955, 0.05202144756913185, 0.056859396398067474, 0.06022631749510765, 0.05005720257759094, 0.07657209783792496, 0.07730535417795181, 0.06079631298780441, 0.05666125565767288, 0.04703343287110329, 0.05011032894253731, 0.0398833304643631, 0.04482155665755272, 0.04887477308511734, 0.052352599799633026, 0.04821676388382912, 0.061349377036094666, 0.0613434873521328, 0.06085579842329025, 0.053653981536626816, 0.05801711976528168, 0.06374802440404892, 0.05252201855182648, 0.039950598031282425, 0.05587185546755791, 0.04351828619837761, 0.04357960447669029, 0.04493175819516182, 0.04700174555182457, 0.03538759425282478, 0.05801337957382202, 0.04652037099003792, 0.05234883353114128, 0.050788722932338715, 0.046482108533382416, 0.04772880673408508, 0.04027509689331055, 0.04679620638489723, 0.04492415115237236, 0.058458734303712845, 0.0525047592818737, 0.0440516322851181, 0.04855634644627571, 0.04203534871339798, 0.045987293124198914, 0.043874140828847885, 0.035027965903282166, 0.05906904488801956, 0.048202455043792725, 0.053421564400196075, 0.04496662691235542, 0.04001488909125328, 0.052561983466148376, 0.05347500368952751, 0.04074205458164215, 0.0447365939617157, 0.03943082317709923, 0.04015001282095909, 0.03765207156538963, 0.041240088641643524, 0.049983955919742584, 0.03712421655654907, 0.03407168388366699, 0.04099346697330475, 0.04333946853876114, 0.05076862499117851, 0.05986346676945686, 0.034676872193813324, 0.05220670998096466, 0.048409316688776016, 0.044421516358852386, 0.08310722559690475, 0.04146679863333702, 0.038750212639570236, 0.04809562861919403, 0.06809548288583755, 0.033073924481868744, 0.050488367676734924, 0.040276870131492615, 0.04633605107665062, 0.03751479834318161, 0.037233129143714905, 0.03814324736595154, 0.047198306769132614, 0.036268021911382675, 0.032241176813840866, 0.029931191354990005, 0.05129766836762428, 0.041141659021377563, 0.03422968462109566, 0.03965562582015991, 0.04199627414345741, 0.03704249486327171, 0.036609698086977005, 0.03340066969394684, 0.03801341727375984, 0.04048169404268265, 0.0495288148522377, 0.03743322566151619, 0.05084061250090599, 0.03841247409582138, 0.051190949976444244, 0.03515157103538513, 0.029509088024497032, 0.04261959716677666, 0.03457425907254219, 0.03831634297966957, 0.0442902110517025, 0.03939133509993553, 0.04606807976961136, 0.02536328323185444, 0.03404363989830017, 0.042490750551223755, 0.03618227317929268, 0.0428827665746212, 0.04919005185365677, 0.03179439529776573, 0.04032646492123604, 0.050798188894987106, 0.031435754150152206, 0.03565392270684242, 0.03385501727461815, 0.03536055237054825, 0.03977854922413826, 0.03394922986626625, 0.037200264632701874, 0.02865925431251526, 0.03958406299352646, 0.0356103889644146, 0.028767647221684456, 0.04487088322639465, 0.037022195756435394, 0.027451572939753532, 0.03204964101314545, 0.030251093208789825, 0.0376770980656147, 0.032389819622039795, 0.03005886636674404, 0.0375666581094265, 0.03159194067120552, 0.024447478353977203, 0.03277599811553955, 0.03468167036771774, 0.028597772121429443, 0.017798127606511116, 0.04427213594317436, 0.04560162499547005, 0.04818687587976456, 0.03336973860859871, 0.04228249937295914, 0.035405635833740234, 0.03331488370895386, 0.03449385240674019, 0.06836924701929092, 0.11014557629823685, 0.05615852773189545, 0.03153211250901222, 0.04199432581663132, 0.03765714168548584, 0.0411941260099411, 0.036581385880708694, 0.04540087655186653, 0.03506054729223251, 0.021032482385635376, 0.03239455074071884, 0.026996830478310585, 0.020440954715013504, 0.027306627482175827, 0.03231291100382805, 0.02900712750852108, 0.03280271217226982, 0.03166242688894272, 0.03131960704922676, 0.044320084154605865, 0.03550402820110321, 0.023565538227558136, 0.018211903050541878, 0.029182322323322296, 0.032580550760030746, 0.024688933044672012, 0.02609322965145111, 0.02867797389626503, 0.023487890139222145, 0.029227254912257195, 0.027453480288386345, 0.02920646034181118, 0.03171771764755249, 0.03236516937613487, 0.032489802688360214, 0.028340116143226624, 0.03189177066087723, 0.02656758390367031, 0.02761087194085121, 0.040753744542598724, 0.02898341976106167, 0.03539203479886055, 0.026517970487475395, 0.032216593623161316, 0.0319330133497715, 0.028415877372026443, 0.0372798852622509, 0.027676789090037346, 0.028328796848654747, 0.02532011829316616, 0.020596344023942947, 0.07288772612810135, 0.05118301883339882, 0.03687262162566185, 0.04506717249751091, 0.04270798712968826, 0.05448927357792854, 0.03210745006799698, 0.035565316677093506, 0.028787391260266304, 0.028306197375059128, 0.023134926334023476, 0.025099098682403564, 0.03350243717432022, 0.03553130477666855, 0.03115778975188732, 0.024146724492311478, 0.02439849264919758, 0.03164220601320267, 0.03058057278394699, 0.024793660268187523, 0.027547944337129593, 0.03301755338907242, 0.025599298998713493, 0.022722888737916946, 0.03410256654024124, 0.029996544122695923, 0.02831433340907097, 0.040530014783144, 0.033333055675029755, 0.018844768404960632, 0.016528500244021416, 0.04122909530997276, 0.021288244053721428]\n",
            "[0.9009862031392243, 0.4468116711227059, 0.3502653799540126, 0.2696338666638279, 0.25198374430883286, 0.18599050913452528, 0.1728057060556288, 0.146985783801161, 0.135292620299855, 0.1319890568212203, 0.12216643823907809, 0.12480278904769716, 0.10178099820505848, 0.10515917758302258, 0.0932519115675973, 0.11260062278025638, 0.08610875177296605, 0.08370668020291312, 0.09027905641383988, 0.07925010508843404, 0.08011247121740028, 0.07992352966426258, 0.07201720606122727, 0.0784911744099454, 0.07750414997336057, 0.0752738658233055, 0.06926748513715789, 0.0704973954082978, 0.06808492624301324, 0.06905425406886306, 0.0643929377592413, 0.061222667010780114, 0.06253560059609627, 0.05784364514985687, 0.06834575153078935, 0.057504328728820164, 0.06067200613581063, 0.060419685033451145, 0.05745471916439268, 0.05705166858256572, 0.06124479631240304, 0.05799337536578542, 0.055935695893480804, 0.05120617744266585, 0.05248791770326309, 0.05091257795254207, 0.055651814023189784, 0.05103068499304925, 0.053383488423705, 0.07338768517650576, 0.06137504766961422, 0.05897956540277636, 0.056496285735967135, 0.051251568440401775, 0.04937418965273475, 0.047048818663559006, 0.07976471027144914, 0.04398778537534679, 0.04475213154468953, 0.05121266273259989, 0.04141125377418015, 0.0417044615370821, 0.07417610260575477, 0.04111283348231496, 0.039877836541126574, 0.044415981972308206, 0.04211630227272243, 0.040914216282198664, 0.03824112910441787, 0.04393278836846492, 0.04142734535254719, 0.03920958597359456, 0.04332274191849164, 0.03844903349793416, 0.038330875937491286, 0.044526032566037946, 0.0725183642022587, 0.04446016387854167, 0.041865012942116815, 0.03989280244145817, 0.03658457126584524, 0.03581181445988002, 0.03755693345315594, 0.035256270515921284, 0.04163263013854318, 0.03510505274024758, 0.03385673823744566, 0.034435356033933426, 0.035545441857761054, 0.0324478491600549, 0.03872697292394674, 0.0363183570264672, 0.03312868194314851, 0.03243602446543847, 0.03192335249124183, 0.030695017413840158, 0.033181176795084075, 0.029290086738075, 0.042872258497246865, 0.02919303786791155, 0.03391290035849275, 0.032936518952307134, 0.03016716714250597, 0.027948474165923852, 0.03854981010177127, 0.030657977805768854, 0.028808301455252806, 0.029515358667967916, 0.03319496163675262, 0.03551044485385022, 0.026849435086929517, 0.03076758532375624, 0.03099943957728129, 0.040481803113852195, 0.03189745441108465, 0.029269080104770556, 0.029797218449727377, 0.027739879261665195, 0.03092574329540665, 0.029635834669231684, 0.029020155755380268, 0.02741861636705016, 0.026433785894742625, 0.02471025388157104, 0.02493198393440897, 0.025014689021810765, 0.022768439537520082, 0.025540116189850245, 0.027450796802462322, 0.038057401402717475, 0.026954481072178856, 0.025945513104920978, 0.02932622788648119, 0.025243738353125933, 0.032596406501428504, 0.027267295926578103, 0.025211595158229627, 0.02723935822701614, 0.02284365101638913, 0.02311908529858521, 0.022066591244731152, 0.02686475692668991, 0.02376918980209509, 0.021740876939527243, 0.022319745274367968, 0.022037725438298218, 0.023152952151248296, 0.020743886315076985, 0.021834347259515195, 0.020546946865441885, 0.02254823708074993, 0.020506596584043597, 0.022655774727750738, 0.041936672922448286, 0.023958789779371454, 0.022165429099791887, 0.022463176229864833, 0.06621270605308191, 0.02993828860896331, 0.03194402899805498, 0.024768848958748597, 0.022901044575319163, 0.02066269439628504, 0.022373255983159014, 0.021839885091152443, 0.02171284304889742, 0.019269416992346803, 0.01928285958125428, 0.018780457011894902, 0.033760757091259364, 0.020185337834466105, 0.018584117920352607, 0.025140218952283133, 0.01925978791791182, 0.019240548513582513, 0.020863464716381036, 0.019340284351001803, 0.018488986216851265, 0.01776875412839893, 0.047670236124558105, 0.0321609760078438, 0.02260281126621041, 0.01839022223334059, 0.03193019196521074, 0.03521729045878276, 0.044501526956853554, 0.022249938202902438, 0.02130664432274589, 0.020106161281785072, 0.01965505916880011, 0.020219250968360192, 0.017329647542061552, 0.018725983959552137, 0.017993368851529135, 0.02750802211893273, 0.017984434363094378, 0.02659243019347436, 0.019380355113688984, 0.019520021410138734, 0.017933305570146746]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeVC09ECTUJJ",
        "colab_type": "code",
        "outputId": "0232905a-8925-4f6d-e952-042e5b0fc1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "# visualize the loss as the network trained\n",
        "from matplotlib import pyplot as plt\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_losses)+1),train_losses, label='Training Loss')\n",
        "plt.plot(range(1,len(val_losses)+1),val_losses,label='Validation Loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = val_losses.index(min(val_losses))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 3) # consistent scale\n",
        "plt.xlim(0, len(val_losses)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w4S0tyfbLgR",
        "colab_type": "text"
      },
      "source": [
        "Accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSye9n88_28v",
        "colab_type": "code",
        "outputId": "3d5284ff-2062-41b2-a518-d9c1f91a9481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "test_loss = test(last_model, device, test_loader)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0181, Precision: 0.9224, Recall: 0.8980, F1 score: 0.9052,   Accuracy: 8975/9337 (96%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5bmXSOTbRH_",
        "colab_type": "text"
      },
      "source": [
        "Visualizing via Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSFpKfiq1O1V",
        "colab_type": "code",
        "outputId": "b1197a13-3b3e-4e6c-f3d4-feb445938a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "nb_classes = 13\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_loader):\n",
        "        inputs = inputs.float()\n",
        "        classes = classes.float()\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "array=np.array(confusion_matrix)\n",
        "\n",
        "gestures=[\"Null\", \"Standing still\", \"Sitting and relaxing\", \"Lying down\", \"Walking\", \"Climbing stairs\", \"Waist bends forward\", \"Frontal elevation of arms\", \"Knees bending (crouching)\", \"Cycling\", \"Jogging\", \"Running\", \"Jump front & back\"]\n",
        "\n",
        "df_cm = pd.DataFrame(array, index = [i for i in gestures],\n",
        "                  columns = [i for i in gestures])\n",
        "# display(df_cm)\n",
        "plt.figure(figsize = (10, 5))\n",
        "ax = sn.heatmap(df_cm, vmin=0, vmax=150, annot=True, fmt=\".0f\")\n",
        "bottom, top = ax.get_ylim()\n",
        "ax.set_ylim(bottom + 0.5, top - 0.5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-iyP7j16ZNa",
        "colab_type": "code",
        "outputId": "6a9daf85-f993-4b97-a03e-ef66625eea1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "for ii in last_model.parameters():\n",
        "    print(ii.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([256, 1, 6, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([256])\n",
            "torch.Size([128, 256, 6, 1])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 5120])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([13, 128])\n",
            "torch.Size([13])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}